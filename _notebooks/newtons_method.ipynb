{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a37a3d9",
   "metadata": {},
   "source": [
    "# Newton’s Method via JAX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363ec53c",
   "metadata": {},
   "source": [
    "# GPU\n",
    "\n",
    "This lecture was built using [hardware](https://jax.quantecon.org/status.html#status-machine-details) that has access to a GPU.\n",
    "\n",
    "To run this lecture on [Google Colab](https://colab.research.google.com/), click on the “play” icon top right, select Colab, and set the runtime environment to include a GPU.\n",
    "\n",
    "To run this lecture on your own machine, you need to install [Google JAX](https://github.com/google/jax)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d240e1a",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this lecture we highlight some of the capabilities of JAX, including JIT\n",
    "compilation and automatic differentiation.\n",
    "\n",
    "The application is computing equilibria via Newton’s method, which we discussed\n",
    "in [a more elementary QuantEcon lecture](https://python.quantecon.org/newton_method.html)\n",
    "\n",
    "Here our focus is on how to apply JAX to this problem.\n",
    "\n",
    "We use the following imports in this lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17589803",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from scipy.optimize import root"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f55d8a0",
   "metadata": {},
   "source": [
    "Let’s check the GPU we are running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6ec5c9",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b3ca4f",
   "metadata": {},
   "source": [
    "## The Equilibrium Problem\n",
    "\n",
    "In this section we describe the market equilibrium problem we will solve with\n",
    "JAX.\n",
    "\n",
    "We begin with a two good case,\n",
    "which is borrowed from [an earlier lecture](https://python.quantecon.org/newton_method.html).\n",
    "\n",
    "Then we shift to higher dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d914d01d",
   "metadata": {},
   "source": [
    "### The Two Goods Market Equilibrium\n",
    "\n",
    "Assume we have a market for two complementary goods where demand depends on the\n",
    "price of both components.\n",
    "\n",
    "We label them good 0 and good 1, with price vector $ p = (p_0, p_1) $.\n",
    "\n",
    "Then the supply of good $ i $ at price $ p $ is,\n",
    "\n",
    "$$\n",
    "q^s_i (p) = b_i \\sqrt{p_i}\n",
    "$$\n",
    "\n",
    "and the demand of good $ i $ at price $ p $ is,\n",
    "\n",
    "$$\n",
    "q^d_i (p) = \\text{exp}(-(a_{i0} p_0 + a_{i1} p_1)) + c_i\n",
    "$$\n",
    "\n",
    "Here $ a_{ij} $, $ b_i $ and $ c_i $ are parameters for $ n \\times n $ square matrix $ A $ and $ n \\times 1 $ parameter vectors $ b $ and $ c $.\n",
    "\n",
    "The excess demand function is,\n",
    "\n",
    "$$\n",
    "e_i(p) = q_i^d(p) - q_i^s(p), \\quad i = 0, 1\n",
    "$$\n",
    "\n",
    "An equilibrium price vector $ p^* $ satisfies $ e_i(p^*) = 0 $.\n",
    "\n",
    "We set\n",
    "\n",
    "$$\n",
    "A = \\begin{pmatrix}\n",
    "            a_{00} & a_{01} \\\\\n",
    "            a_{10} & a_{11}\n",
    "        \\end{pmatrix},\n",
    "            \\qquad\n",
    "    b = \\begin{pmatrix}\n",
    "            b_0 \\\\\n",
    "            b_1\n",
    "        \\end{pmatrix}\n",
    "    \\qquad \\text{and} \\qquad\n",
    "    c = \\begin{pmatrix}\n",
    "            c_0 \\\\\n",
    "            c_1\n",
    "        \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "for this particular question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9e6058",
   "metadata": {},
   "source": [
    "### A High-Dimensional Version\n",
    "\n",
    "Let’s now shift to a linear algebra formulation, which alllows us to handle\n",
    "arbitrarily many goods.\n",
    "\n",
    "The supply function remains unchanged,\n",
    "\n",
    "$$\n",
    "q^s (p) =b \\sqrt{p}\n",
    "$$\n",
    "\n",
    "The demand function becomes\n",
    "\n",
    "$$\n",
    "q^d (p) = \\text{exp}(- A \\cdot p) + c\n",
    "$$\n",
    "\n",
    "Our new excess demand function is\n",
    "\n",
    "$$\n",
    "e(p) = \\text{exp}(- A \\cdot p) + c - b \\sqrt{p}\n",
    "$$\n",
    "\n",
    "The function below calculates the excess demand for the given parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a896c7",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def e(p, A, b, c):\n",
    "    return jnp.exp(- A @ p) + c - b * jnp.sqrt(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab24fa8",
   "metadata": {},
   "source": [
    "## Computation\n",
    "\n",
    "In this section we describe and then implement the solution method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759e56c9",
   "metadata": {},
   "source": [
    "### Newton’s Method\n",
    "\n",
    "We use a multivariate version of Newton’s method to compute the equilibrium price.\n",
    "\n",
    "The rule for updating a guess $ p_n $ of the price vector is\n",
    "\n",
    "\n",
    "<a id='equation-multi-newton'></a>\n",
    "$$\n",
    "p_{n+1} = p_n - J_e(p_n)^{-1} e(p_n) \\tag{3.1}\n",
    "$$\n",
    "\n",
    "Here $ J_e(p_n) $ is the Jacobian of $ e $ evaluated at $ p_n $.\n",
    "\n",
    "Iteration starts from initial guess $ p_0 $.\n",
    "\n",
    "Instead of coding the Jacobian by hand, we use `jax.jacobian()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9625bc6a",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def newton(f, x_0, tol=1e-5, max_iter=15):\n",
    "    x = x_0\n",
    "    f_jac = jax.jacobian(f)\n",
    "    q = jax.jit(lambda x: x - jnp.linalg.solve(f_jac(x), f(x)))\n",
    "    error = tol + 1\n",
    "    n = 0\n",
    "    while error > tol:\n",
    "        n += 1\n",
    "        if(n > max_iter):\n",
    "            raise Exception('Max iteration reached without convergence')\n",
    "        y = q(x)\n",
    "        if jnp.any(jnp.isnan(y)):\n",
    "            raise Exception('Solution not found with NaN generated')\n",
    "        error = jnp.linalg.norm(x - y)\n",
    "        x = y\n",
    "        print(f'iteration {n}, error = {error}')\n",
    "    print('\\n' + f'Result = {x} \\n')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc48c054",
   "metadata": {},
   "source": [
    "### Application\n",
    "\n",
    "Let’s now apply the method just described to investigate a large market with 5,000 goods.\n",
    "\n",
    "We randomly generate the matrix $ A $ and set the parameter vectors $ b \\text{ and } c $ to $ 1 $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d80178",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "dim = 5_000\n",
    "seed = 32\n",
    "\n",
    "# Create a random matrix A and normalize the rows to sum to one\n",
    "key = jax.random.PRNGKey(seed)\n",
    "\n",
    "A = jax.random.uniform(key, [dim, dim])\n",
    "\n",
    "s = jnp.sum(A, axis=0)\n",
    "A = A / s\n",
    "\n",
    "# Set up b and c\n",
    "b = jnp.ones(dim)\n",
    "c = jnp.ones(dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea0f480",
   "metadata": {},
   "source": [
    "Here’s our initial condition $ p_0 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b746d8e",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "init_p = jnp.ones(dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200e24e2",
   "metadata": {},
   "source": [
    "By leveraging the power of Newton’s method, JAX accelerated linear algebra,\n",
    "automatic differentiation, and a GPU, we obtain a relatively small error for\n",
    "this very large problem in just a few seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0505a39c",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "p = newton(lambda p: e(p, A, b, c), init_p).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322cf1f1",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "jnp.max(jnp.abs(e(p, A, b, c)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883fc46d",
   "metadata": {},
   "source": [
    "With the same tolerance, SciPy’s `root` function takes much longer to run,\n",
    "even with the Jacobian supplied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4df067",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "solution = root(lambda p: e(p, A, b, c),\n",
    "                init_p,\n",
    "                jac=lambda p: jax.jacobian(e)(p, A, b, c),\n",
    "                method='hybr',\n",
    "                tol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a332cc7",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "p = solution.x\n",
    "jnp.max(jnp.abs(e(p, A, b, c)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e2319c",
   "metadata": {},
   "source": [
    "The result is also less accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b53160b",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd86bdc",
   "metadata": {},
   "source": [
    "## Exercise 3.1\n",
    "\n",
    "Consider a three-dimensional extension of [the Solow fixed point\n",
    "problem](https://python.quantecon.org/newton_method.html#the-solow-model) with\n",
    "\n",
    "$$\n",
    "A = \\begin{pmatrix}\n",
    "            2 & 3 & 3 \\\\\n",
    "            2 & 4 & 2 \\\\\n",
    "            1 & 5 & 1 \\\\\n",
    "        \\end{pmatrix},\n",
    "            \\quad\n",
    "s = 0.2, \\quad α = 0.5, \\quad δ = 0.8\n",
    "$$\n",
    "\n",
    "As before the law of motion is\n",
    "\n",
    "$$\n",
    "k_{t+1} = g(k_t) \\quad \\text{where} \\quad\n",
    "    g(k) := sAk^\\alpha + (1-\\delta) k\n",
    "$$\n",
    "\n",
    "However $ k_t $ is now a $ 3 \\times 1 $ vector.\n",
    "\n",
    "Solve for the fixed point using Newton’s method with the following initial values:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    k1_{0} &= (1, 1, 1) \\\\\n",
    "    k2_{0} &= (3, 5, 5) \\\\\n",
    "    k3_{0} &= (50, 50, 50)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "- The computation of the fixed point is equivalent to computing $ k^* $ such that $ f(k^*) - k^* = 0 $.  \n",
    "- If you are unsure about your solution, you can start with the solved example:  \n",
    "\n",
    "\n",
    "$$\n",
    "A = \\begin{pmatrix}\n",
    "            2 & 0 & 0 \\\\\n",
    "            0 & 2 & 0 \\\\\n",
    "            0 & 0 & 2 \\\\\n",
    "        \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "with $ s = 0.3 $, $ α = 0.3 $, and $ δ = 0.4 $ and starting value:\n",
    "\n",
    "$$\n",
    "k_0 = (1, 1, 1)\n",
    "$$\n",
    "\n",
    "The result should converge to the [analytical solution](https://python.quantecon.org/newton_method.html#solved-k)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaae4c1",
   "metadata": {},
   "source": [
    "## Solution to[ Exercise 3.1](https://jax.quantecon.org/#newton_ex1)\n",
    "\n",
    "Let’s first define the parameters for this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0082a095",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "A = jnp.array([[2.0, 3.0, 3.0],\n",
    "               [2.0, 4.0, 2.0],\n",
    "               [1.0, 5.0, 1.0]])\n",
    "s = 0.2\n",
    "α = 0.5\n",
    "δ = 0.8\n",
    "initLs = [jnp.ones(3),\n",
    "          jnp.array([3.0, 5.0, 5.0]),\n",
    "          jnp.repeat(50.0, 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbac10d4",
   "metadata": {},
   "source": [
    "Then define the multivariate version of the formula for the [law of motion of captial](https://python.quantecon.org/newton_method.html#solow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad72b6cb",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def multivariate_solow(k, A=A, s=s, α=α, δ=δ):\n",
    "    return s * jnp.dot(A, k**α) + (1 - δ) * k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6062bad",
   "metadata": {},
   "source": [
    "Let’s run through each starting value and see the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d431ef47",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "attempt = 1\n",
    "for init in initLs:\n",
    "    print(f'Attempt {attempt}: Starting value is {init} \\n')\n",
    "    %time k = newton(lambda k: multivariate_solow(k) - k, \\\n",
    "                     init).block_until_ready()\n",
    "    print('-'*64)\n",
    "    attempt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa60574",
   "metadata": {},
   "source": [
    "We find that the results are invariant to the starting values given the well-defined property of this question.\n",
    "\n",
    "But the number of iterations it takes to converge is dependent on the starting values.\n",
    "\n",
    "Let substitute the output back to the formulate to check our last result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a50df6",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "multivariate_solow(k) - k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49e9dfb",
   "metadata": {},
   "source": [
    "Note the error is very small.\n",
    "\n",
    "We can also test our results on the known solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da137988",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "A = jnp.array([[2.0, 0.0, 0.0],\n",
    "               [0.0, 2.0, 0.0],\n",
    "               [0.0, 0.0, 2.0]])\n",
    "s = 0.3\n",
    "α = 0.3\n",
    "δ = 0.4\n",
    "init = jnp.repeat(1.0, 3)\n",
    "%time k = newton(lambda k: multivariate_solow(k, A=A, s=s, α=α, δ=δ) - k, \\\n",
    "                 init).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074ddbdb",
   "metadata": {},
   "source": [
    "The result is very close to the ground truth but still slightly different.\n",
    "\n",
    "We can increase the precision of the floating point numbers and restrict the tolerance to obtain a more accurate approximation (see detailed discussion in the [lecture on JAX](https://python-programming.quantecon.org/jax_intro.html#differences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5336b634",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# We will use 64 bit floats with JAX in order to increase the precision.\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "init = init.astype('float64')\n",
    "\n",
    "%time k = newton(lambda k: multivariate_solow(k, A=A, s=s, α=α, δ=δ) - k,\\\n",
    "                 init,\\\n",
    "                 tol=1e-7).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179efd6c",
   "metadata": {},
   "source": [
    "We can see it steps towards a more accurate solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d298117a",
   "metadata": {},
   "source": [
    "## Exercise 3.2\n",
    "\n",
    "In this exercise, let’s try different initial values and check how Newton’s method responds to different starting points.\n",
    "\n",
    "Let’s define a three-good problem with the following default values:\n",
    "\n",
    "$$\n",
    "A = \\begin{pmatrix}\n",
    "            0.2 & 0.1 & 0.7 \\\\\n",
    "            0.3 & 0.2 & 0.5 \\\\\n",
    "            0.1 & 0.8 & 0.1 \\\\\n",
    "        \\end{pmatrix},\n",
    "            \\qquad\n",
    "b = \\begin{pmatrix}\n",
    "            1 \\\\\n",
    "            1 \\\\\n",
    "            1\n",
    "        \\end{pmatrix}\n",
    "    \\qquad \\text{and} \\qquad\n",
    "c = \\begin{pmatrix}\n",
    "            1 \\\\\n",
    "            1 \\\\\n",
    "            1\n",
    "        \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "For this exercise, use the following extreme price vectors as initial values:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    p1_{0} &= (5, 5, 5) \\\\\n",
    "    p2_{0} &= (1, 1, 1) \\\\\n",
    "    p3_{0} &= (4.5, 0.1, 4)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Set the tolerance to $ 10^{-15} $ for more accurate output.\n",
    "\n",
    "Similar to [exercise 1](#newton_ex1), enabling `float64` for JAX can improve the precision of our results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd4959a",
   "metadata": {},
   "source": [
    "## Solution to[ Exercise 3.2](https://jax.quantecon.org/#newton_ex2)\n",
    "\n",
    "Define parameters and initial values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1935e851",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "A = jnp.array([\n",
    "    [0.2, 0.1, 0.7],\n",
    "    [0.3, 0.2, 0.5],\n",
    "    [0.1, 0.8, 0.1]\n",
    "])\n",
    "b = jnp.array([1.0, 1.0, 1.0])\n",
    "c = jnp.array([1.0, 1.0, 1.0])\n",
    "initLs = [jnp.repeat(5.0, 3),\n",
    "          jnp.array([4.5, 0.1, 4.0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56904e4b",
   "metadata": {},
   "source": [
    "Let’s run through each initial guess and check the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e27492",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "attempt = 1\n",
    "for init in initLs:\n",
    "    print(f'Attempt {attempt}: Starting value is {init} \\n')\n",
    "    init = init.astype('float64')\n",
    "    %time p = newton(lambda p: e(p, A, b, c), \\\n",
    "                 init, \\\n",
    "                 tol=1e-15, max_iter=15).block_until_ready()\n",
    "    print('-'*64)\n",
    "    attempt +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545430d8",
   "metadata": {},
   "source": [
    "We can find that Newton’s method may fail for some starting values.\n",
    "\n",
    "Sometimes it may take a few initial guesses to achieve convergence.\n",
    "\n",
    "Substitute the result back to the formula to check our result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e5927f",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "e(p, A, b, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4615f96",
   "metadata": {},
   "source": [
    "We can see the result is very accurate."
   ]
  }
 ],
 "metadata": {
  "date": 1688450071.6651814,
  "filename": "newtons_method.md",
  "kernelspec": {
   "display_name": "Python",
   "language": "python3",
   "name": "python3"
  },
  "title": "Newton’s Method via JAX"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}