{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9422c0f9",
   "metadata": {},
   "source": [
    "# Optimal Investment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f14c8dd",
   "metadata": {},
   "source": [
    "# GPU\n",
    "\n",
    "This lecture was built using a machine with JAX installed and access to a GPU.\n",
    "\n",
    "To run this lecture on [Google Colab](https://colab.research.google.com/), click on the “play” icon top right, select Colab, and set the runtime environment to include a GPU.\n",
    "\n",
    "To run this lecture on your own machine, you need to install [Google JAX](https://github.com/google/jax).\n",
    "\n",
    "In addition to JAX and Anaconda, this lecture will need the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99e5c9d",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade quantecon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73c8a07",
   "metadata": {},
   "source": [
    "We study a monopolist who faces inverse demand curve\n",
    "\n",
    "$$\n",
    "P_t = a_0 - a_1 Y_t + Z_t,\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "- $ P_t $ is price,  \n",
    "- $ Y_t $ is output and  \n",
    "- $ Z_t $ is a demand shock.  \n",
    "\n",
    "\n",
    "We assume that $ Z_t $ is a discretized AR(1) process, specified below.\n",
    "\n",
    "Current profits are\n",
    "\n",
    "$$\n",
    "P_t Y_t - c Y_t - \\gamma (Y_{t+1} - Y_t)^2\n",
    "$$\n",
    "\n",
    "Combining with the demand curve and writing $ y, y' $ for $ Y_t, Y_{t+1} $, this becomes\n",
    "\n",
    "$$\n",
    "r(y, z, y') := (a_0 - a_1  y + z - c) y - γ  (y' - y)^2\n",
    "$$\n",
    "\n",
    "The firm maximizes present value of expected discounted profits.  The Bellman equation is\n",
    "\n",
    "$$\n",
    "v(y, z) = \\max_{y'} \\left\\{ r(y, z, y') + β \\sum_{z'} v(y', z') Q(z, z') \\right\\}.\n",
    "$$\n",
    "\n",
    "We discretize $ y $ to a finite grid `y_grid`.\n",
    "\n",
    "In essence, the firm tries to choose output close to the monopolist profit maximizer, given $ Z_t $, but is constrained by adjustment costs.\n",
    "\n",
    "Let’s begin with the following imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dab5118",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import quantecon as qe\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1256f6a",
   "metadata": {},
   "source": [
    "Let’s check the GPU we are running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69f7a3e",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa0a145",
   "metadata": {},
   "source": [
    "We will use 64 bit floats with JAX in order to increase the precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d096b29",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "jax.config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270b3c37",
   "metadata": {},
   "source": [
    "Let’s define a function to create an investment model using the given parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5996b422",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def create_investment_model(\n",
    "        r=0.01,                              # Interest rate\n",
    "        a_0=10.0, a_1=1.0,                   # Demand parameters\n",
    "        γ=25.0, c=1.0,                       # Adjustment and unit cost\n",
    "        y_min=0.0, y_max=20.0, y_size=100,   # Grid for output\n",
    "        ρ=0.9, ν=1.0,                        # AR(1) parameters\n",
    "        z_size=150):                         # Grid size for shock\n",
    "    \"\"\"\n",
    "    A function that takes in parameters and returns an instance of Model that\n",
    "    contains data for the investment problem.\n",
    "    \"\"\"\n",
    "    β = 1 / (1 + r)\n",
    "    y_grid = jnp.linspace(y_min, y_max, y_size)\n",
    "    mc = qe.tauchen(z_size, ρ, ν)\n",
    "    z_grid, Q = mc.state_values, mc.P\n",
    "\n",
    "    # Break up parameters into static and nonstatic components\n",
    "    constants = β, a_0, a_1, γ, c\n",
    "    sizes = y_size, z_size\n",
    "    arrays = y_grid, z_grid, Q\n",
    "\n",
    "    # Shift arrays to the device (e.g., GPU)\n",
    "    arrays = tuple(map(jax.device_put, arrays))\n",
    "    return constants, sizes, arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5463717a",
   "metadata": {},
   "source": [
    "Let’s re-write the vectorized version of the right-hand side of the\n",
    "Bellman equation (before maximization), which is a 3D array representing\n",
    "\n",
    "$$\n",
    "B(y, z, y') = r(y, z, y') + \\beta \\sum_{z'} v(y', z') Q(z, z')\n",
    "$$\n",
    "\n",
    "for all $ (y, z, y') $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2633e3c6",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def B(v, constants, sizes, arrays):\n",
    "    \"\"\"\n",
    "    A vectorized version of the right-hand side of the Bellman equation\n",
    "    (before maximization)\n",
    "    \"\"\"\n",
    "\n",
    "    # Unpack\n",
    "    β, a_0, a_1, γ, c = constants\n",
    "    y_size, z_size = sizes\n",
    "    y_grid, z_grid, Q = arrays\n",
    "\n",
    "    # Compute current rewards r(y, z, yp) as array r[i, j, ip]\n",
    "    y  = jnp.reshape(y_grid, (y_size, 1, 1))    # y[i]   ->  y[i, j, ip]\n",
    "    z  = jnp.reshape(z_grid, (1, z_size, 1))    # z[j]   ->  z[i, j, ip]\n",
    "    yp = jnp.reshape(y_grid, (1, 1, y_size))    # yp[ip] -> yp[i, j, ip]\n",
    "    r = (a_0 - a_1 * y + z - c) * y - γ * (yp - y)**2\n",
    "\n",
    "    # Calculate continuation rewards at all combinations of (y, z, yp)\n",
    "    v = jnp.reshape(v, (1, 1, y_size, z_size))  # v[ip, jp] -> v[i, j, ip, jp]\n",
    "    Q = jnp.reshape(Q, (1, z_size, 1, z_size))  # Q[j, jp]  -> Q[i, j, ip, jp]\n",
    "    EV = jnp.sum(v * Q, axis=3)                 # sum over last index jp\n",
    "\n",
    "    # Compute the right-hand side of the Bellman equation\n",
    "    return r + β * EV\n",
    "\n",
    "# Create a jitted function\n",
    "B = jax.jit(B, static_argnums=(2,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ec8fca",
   "metadata": {},
   "source": [
    "We define a function to compute the current rewards $ r_\\sigma $ given policy $ \\sigma $,\n",
    "which is defined as the vector\n",
    "\n",
    "$$\n",
    "r_\\sigma(y, z) := r(y, z, \\sigma(y, z))\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf47111",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def compute_r_σ(σ, constants, sizes, arrays):\n",
    "    \"\"\"\n",
    "    Compute the array r_σ[i, j] = r[i, j, σ[i, j]], which gives current\n",
    "    rewards given policy σ.\n",
    "    \"\"\"\n",
    "\n",
    "    # Unpack model\n",
    "    β, a_0, a_1, γ, c = constants\n",
    "    y_size, z_size = sizes\n",
    "    y_grid, z_grid, Q = arrays\n",
    "\n",
    "    # Compute r_σ[i, j]\n",
    "    y = jnp.reshape(y_grid, (y_size, 1))\n",
    "    z = jnp.reshape(z_grid, (1, z_size))\n",
    "    yp = y_grid[σ]\n",
    "    r_σ = (a_0 - a_1 * y + z - c) * y - γ * (yp - y)**2\n",
    "\n",
    "    return r_σ\n",
    "\n",
    "\n",
    "# Create the jitted function\n",
    "compute_r_σ = jax.jit(compute_r_σ, static_argnums=(2,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918713bf",
   "metadata": {},
   "source": [
    "Define the Bellman operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8606b912",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def T(v, constants, sizes, arrays):\n",
    "    \"\"\"The Bellman operator.\"\"\"\n",
    "    return jnp.max(B(v, constants, sizes, arrays), axis=2)\n",
    "\n",
    "T = jax.jit(T, static_argnums=(2,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea44dc8",
   "metadata": {},
   "source": [
    "The following function computes a v-greedy policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1974bf",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def get_greedy(v, constants, sizes, arrays):\n",
    "    \"Computes a v-greedy policy, returned as a set of indices.\"\n",
    "    return jnp.argmax(B(v, constants, sizes, arrays), axis=2)\n",
    "\n",
    "get_greedy = jax.jit(get_greedy, static_argnums=(2,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339a4b44",
   "metadata": {},
   "source": [
    "Define the $ \\sigma $-policy operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebea2473",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def T_σ(v, σ, constants, sizes, arrays):\n",
    "    \"\"\"The σ-policy operator.\"\"\"\n",
    "\n",
    "    # Unpack model\n",
    "    β, a_0, a_1, γ, c = constants\n",
    "    y_size, z_size = sizes\n",
    "    y_grid, z_grid, Q = arrays\n",
    "\n",
    "    r_σ = compute_r_σ(σ, constants, sizes, arrays)\n",
    "\n",
    "    # Compute the array v[σ[i, j], jp]\n",
    "    zp_idx = jnp.arange(z_size)\n",
    "    zp_idx = jnp.reshape(zp_idx, (1, 1, z_size))\n",
    "    σ = jnp.reshape(σ, (y_size, z_size, 1))\n",
    "    V = v[σ, zp_idx]\n",
    "\n",
    "    # Convert Q[j, jp] to Q[i, j, jp]\n",
    "    Q = jnp.reshape(Q, (1, z_size, z_size))\n",
    "\n",
    "    # Calculate the expected sum Σ_jp v[σ[i, j], jp] * Q[i, j, jp]\n",
    "    Ev = jnp.sum(V * Q, axis=2)\n",
    "\n",
    "    return r_σ + β * Ev\n",
    "\n",
    "T_σ = jax.jit(T_σ, static_argnums=(3,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfb065e",
   "metadata": {},
   "source": [
    "Next, we want to computes the lifetime value of following policy $ \\sigma $.\n",
    "\n",
    "This lifetime value is a function $ v_\\sigma $ that satisfies\n",
    "\n",
    "$$\n",
    "v_\\sigma(y, z) = r_\\sigma(y, z) + \\beta \\sum_{z'} v_\\sigma(\\sigma(y, z), z') Q(z, z')\n",
    "$$\n",
    "\n",
    "We wish to solve this equation for $ v_\\sigma $.\n",
    "\n",
    "Suppose we define the linear operator $ L_\\sigma $ by\n",
    "\n",
    "$$\n",
    "(L_\\sigma v)(y, z) = v(y, z) - \\beta \\sum_{z'} v(\\sigma(y, z), z') Q(z, z')\n",
    "$$\n",
    "\n",
    "With this notation, the problem is to solve for $ v $ via\n",
    "\n",
    "$$\n",
    "(L_{\\sigma} v)(y, z) = r_\\sigma(y, z)\n",
    "$$\n",
    "\n",
    "In vector for this is $ L_\\sigma v = r_\\sigma $, which tells us that the function\n",
    "we seek is\n",
    "\n",
    "$$\n",
    "v_\\sigma = L_\\sigma^{-1} r_\\sigma\n",
    "$$\n",
    "\n",
    "JAX allows us to solve linear systems defined in terms of operators; the first\n",
    "step is to define the function $ L_{\\sigma} $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc302bfb",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def L_σ(v, σ, constants, sizes, arrays):\n",
    "\n",
    "    β, a_0, a_1, γ, c = constants\n",
    "    y_size, z_size = sizes\n",
    "    y_grid, z_grid, Q = arrays\n",
    "\n",
    "    # Set up the array v[σ[i, j], jp]\n",
    "    zp_idx = jnp.arange(z_size)\n",
    "    zp_idx = jnp.reshape(zp_idx, (1, 1, z_size))\n",
    "    σ = jnp.reshape(σ, (y_size, z_size, 1))\n",
    "    V = v[σ, zp_idx]\n",
    "\n",
    "    # Expand Q[j, jp] to Q[i, j, jp]\n",
    "    Q = jnp.reshape(Q, (1, z_size, z_size))\n",
    "\n",
    "    # Compute and return v[i, j] - β Σ_jp v[σ[i, j], jp] * Q[j, jp]\n",
    "    return v - β * jnp.sum(V * Q, axis=2)\n",
    "\n",
    "L_σ = jax.jit(L_σ, static_argnums=(3,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2124671a",
   "metadata": {},
   "source": [
    "Now we can define a function to compute $ v_{\\sigma} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9236d0",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def get_value(σ, constants, sizes, arrays):\n",
    "\n",
    "    # Unpack\n",
    "    β, a_0, a_1, γ, c = constants\n",
    "    y_size, z_size = sizes\n",
    "    y_grid, z_grid, Q = arrays\n",
    "\n",
    "    r_σ = compute_r_σ(σ, constants, sizes, arrays)\n",
    "\n",
    "    # Reduce L_σ to a function in v\n",
    "    partial_L_σ = lambda v: L_σ(v, σ, constants, sizes, arrays)\n",
    "\n",
    "    return jax.scipy.sparse.linalg.bicgstab(partial_L_σ, r_σ)[0]\n",
    "\n",
    "get_value = jax.jit(get_value, static_argnums=(2,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16157195",
   "metadata": {},
   "source": [
    "We use successive approximation for VFI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0128db",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def successive_approx_jax(T,                     # Operator (callable)\n",
    "                          x_0,                   # Initial condition                \n",
    "                          tol=1e-6,              # Error tolerance\n",
    "                          max_iter=10_000):      # Max iteration bound\n",
    "    def body_fun(k_x_err):\n",
    "        k, x, error = k_x_err\n",
    "        x_new = T(x)\n",
    "        error = jnp.max(jnp.abs(x_new - x))\n",
    "        return k + 1, x_new, error\n",
    "\n",
    "    def cond_fun(k_x_err):\n",
    "        k, x, error = k_x_err\n",
    "        return jnp.logical_and(error > tol, k < max_iter)\n",
    "\n",
    "    k, x, error = jax.lax.while_loop(cond_fun, body_fun, (1, x_0, tol + 1))\n",
    "    return x\n",
    "\n",
    "successive_approx_jax = jax.jit(successive_approx_jax, static_argnums=(0,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117bf966",
   "metadata": {},
   "source": [
    "For OPI we’ll add a compiled routine that computes $ T_σ^m v $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd38de2",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def iterate_policy_operator(σ, v, m, params, sizes, arrays):\n",
    "\n",
    "    def update(i, v):\n",
    "        v = T_σ(v, σ, params, sizes, arrays)\n",
    "        return v\n",
    "    \n",
    "    v = jax.lax.fori_loop(0, m, update, v)\n",
    "    return v\n",
    "\n",
    "iterate_policy_operator = jax.jit(iterate_policy_operator,\n",
    "                                  static_argnums=(4,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df10a8cb",
   "metadata": {},
   "source": [
    "Finally, we introduce the solvers that implement VFI, HPI and OPI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4a03fa",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def value_function_iteration(model, tol=1e-5):\n",
    "    \"\"\"\n",
    "    Implements value function iteration.\n",
    "    \"\"\"\n",
    "    params, sizes, arrays = model\n",
    "    vz = jnp.zeros(sizes)\n",
    "    _T = lambda v: T(v, params, sizes, arrays)\n",
    "    v_star = successive_approx_jax(_T, vz, tol=tol)\n",
    "    return get_greedy(v_star, params, sizes, arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf40bab",
   "metadata": {},
   "source": [
    "For OPI we will use a compiled JAX `lax.while_loop` operation to speed execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b728f918",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def opi_loop(params, sizes, arrays, m, tol, max_iter):\n",
    "    \"\"\"\n",
    "    Implements optimistic policy iteration (see dp.quantecon.org) with \n",
    "    step size m.\n",
    "\n",
    "    \"\"\"\n",
    "    v_init = jnp.zeros(sizes)\n",
    "\n",
    "    def condition_function(inputs):\n",
    "        i, v, error = inputs\n",
    "        return jnp.logical_and(error > tol, i < max_iter)\n",
    "\n",
    "    def update(inputs):\n",
    "        i, v, error = inputs\n",
    "        last_v = v\n",
    "        σ = get_greedy(v, params, sizes, arrays)\n",
    "        v = iterate_policy_operator(σ, v, m, params, sizes, arrays)\n",
    "        error = jnp.max(jnp.abs(v - last_v))\n",
    "        i += 1\n",
    "        return i, v, error\n",
    "\n",
    "    num_iter, v, error = jax.lax.while_loop(condition_function,\n",
    "                                            update,\n",
    "                                            (0, v_init, tol + 1))\n",
    "\n",
    "    return get_greedy(v, params, sizes, arrays)\n",
    "\n",
    "opi_loop = jax.jit(opi_loop, static_argnums=(1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d718f0ba",
   "metadata": {},
   "source": [
    "Here’s a friendly interface to OPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd3cdb5",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def optimistic_policy_iteration(model, m=10, tol=1e-5, max_iter=10_000):\n",
    "    params, sizes, arrays = model\n",
    "    σ_star = opi_loop(params, sizes, arrays, m, tol, max_iter)\n",
    "    return σ_star"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e662782b",
   "metadata": {},
   "source": [
    "Here’s HPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423c159b",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def howard_policy_iteration(model, maxiter=250):\n",
    "    \"\"\"\n",
    "    Implements Howard policy iteration (see dp.quantecon.org)\n",
    "    \"\"\"\n",
    "    params, sizes, arrays = model\n",
    "    σ = jnp.zeros(sizes, dtype=int)\n",
    "    i, error = 0, 1.0\n",
    "    while error > 0 and i < maxiter:\n",
    "        v_σ = get_value(σ, params, sizes, arrays)\n",
    "        σ_new = get_greedy(v_σ, params, sizes, arrays)\n",
    "        error = jnp.max(jnp.abs(σ_new - σ))\n",
    "        σ = σ_new\n",
    "        i = i + 1\n",
    "        print(f\"Concluded loop {i} with error {error}.\")\n",
    "    return σ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7910cdf",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "model = create_investment_model()\n",
    "constants, sizes, arrays = model\n",
    "β, a_0, a_1, γ, c = constants\n",
    "y_size, z_size = sizes\n",
    "y_grid, z_grid, Q = arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e54f284",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "print(\"Starting HPI.\")\n",
    "%time σ_star_hpi = howard_policy_iteration(model).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac210f01",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# Now time it without compile time\n",
    "start = time()\n",
    "σ_star_hpi = howard_policy_iteration(model).block_until_ready()\n",
    "hpi_without_compile = time() - start\n",
    "print(σ_star_hpi)\n",
    "print(f\"HPI completed in {hpi_without_compile} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d602b0da",
   "metadata": {},
   "source": [
    "Here’s the plot of the Howard policy, as a function of $ y $ at the highest and lowest values of $ z $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dd8895",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "ax.plot(y_grid, y_grid, \"k--\", label=\"45\")\n",
    "ax.plot(y_grid, y_grid[σ_star_hpi[:, 1]], label=\"$\\\\sigma^{*}_{HPI}(\\cdot, z_1)$\")\n",
    "ax.plot(y_grid, y_grid[σ_star_hpi[:, -1]], label=\"$\\\\sigma^{*}_{HPI}(\\cdot, z_N)$\")\n",
    "ax.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6951d4c",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "print(\"Starting VFI.\")\n",
    "%time σ_star_vfi = value_function_iteration(model).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f11ccad",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# Now time it without compile time\n",
    "start = time()\n",
    "σ_star_vfi = value_function_iteration(model).block_until_ready()\n",
    "vfi_without_compile = time() - start\n",
    "print(σ_star_vfi)\n",
    "print(f\"VFI completed in {vfi_without_compile} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5702770d",
   "metadata": {},
   "source": [
    "Here’s the plot of the VFI, as a function of $ y $ at the highest and lowest values of $ z $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17102a55",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "ax.plot(y_grid, y_grid, \"k--\", label=\"45\")\n",
    "ax.plot(y_grid, y_grid[σ_star_vfi[:, 1]], label=\"$\\\\sigma^{*}_{VFI}(\\cdot, z_1)$\")\n",
    "ax.plot(y_grid, y_grid[σ_star_vfi[:, -1]], label=\"$\\\\sigma^{*}_{VFI}(\\cdot, z_N)$\")\n",
    "ax.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f57166",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "print(\"Starting OPI.\")\n",
    "%time σ_star_opi = optimistic_policy_iteration(model, m=100).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e1812e",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# Now time it without compile time\n",
    "start = time()\n",
    "σ_star_opi = optimistic_policy_iteration(model, m=100).block_until_ready()\n",
    "opi_without_compile = time() - start\n",
    "print(σ_star_opi)\n",
    "print(f\"OPI completed in {opi_without_compile} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a37c38d",
   "metadata": {},
   "source": [
    "Here’s the plot of the optimal policy, as a function of $ y $ at the highest and lowest values of $ z $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df32a010",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "ax.plot(y_grid, y_grid, \"k--\", label=\"45\")\n",
    "ax.plot(y_grid, y_grid[σ_star_opi[:, 1]], label=\"$\\\\sigma^{*}_{OPI}(\\cdot, z_1)$\")\n",
    "ax.plot(y_grid, y_grid[σ_star_opi[:, -1]], label=\"$\\\\sigma^{*}_{OPI}(\\cdot, z_N)$\")\n",
    "ax.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c49bc78",
   "metadata": {},
   "source": [
    "We observe that all the solvers produce the same output from the above three plots.\n",
    "\n",
    "Let’s plot the time taken by each of the solvers and compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcfdbf5",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "m_vals = range(5, 600, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fd36e2",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "print(\"Running Howard policy iteration.\")\n",
    "%time σ_hpi = howard_policy_iteration(model).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165f056d",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# Now time it without compile time\n",
    "start = time()\n",
    "σ_hpi = howard_policy_iteration(model).block_until_ready()\n",
    "hpi_without_compile = time() - start\n",
    "print(f\"HPI completed in {hpi_without_compile} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aa4b88",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "print(\"Running value function iteration.\")\n",
    "%time σ_vfi = value_function_iteration(model, tol=1e-5).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad684d7",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# Now time it without compile time\n",
    "start = time()\n",
    "σ_vfi = value_function_iteration(model, tol=1e-5).block_until_ready()\n",
    "vfi_without_compile = time() - start\n",
    "print(f\"VFI completed in {vfi_without_compile} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f661adea",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "opi_times = []\n",
    "for m in m_vals:\n",
    "    print(f\"Running optimistic policy iteration with m={m}.\")\n",
    "    σ_opi = optimistic_policy_iteration(model, m=m, tol=1e-5).block_until_ready()\n",
    "\n",
    "    # Now time it without compile time\n",
    "    start = time()\n",
    "    σ_opi = optimistic_policy_iteration(model, m=m, tol=1e-5).block_until_ready()\n",
    "    opi_without_compile = time() - start\n",
    "    print(f\"OPI with m={m} completed in {opi_without_compile} seconds.\")\n",
    "    opi_times.append(opi_without_compile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b70afc4",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "ax.plot(m_vals, jnp.full(len(m_vals), hpi_without_compile),\n",
    "        lw=2, label=\"Howard policy iteration\")\n",
    "ax.plot(m_vals, jnp.full(len(m_vals), vfi_without_compile),\n",
    "        lw=2, label=\"value function iteration\")\n",
    "ax.plot(m_vals, opi_times, lw=2, label=\"optimistic policy iteration\")\n",
    "ax.legend(fontsize=12, frameon=False)\n",
    "ax.set_xlabel(\"$m$\", fontsize=12)\n",
    "ax.set_ylabel(\"time(s)\", fontsize=12)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "date": 1750763757.6148756,
  "filename": "opt_invest.md",
  "kernelspec": {
   "display_name": "Python",
   "language": "python3",
   "name": "python3"
  },
  "title": "Optimal Investment"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}