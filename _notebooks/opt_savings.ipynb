{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e3ae93b",
   "metadata": {},
   "source": [
    "# Optimal Savings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d3b0e4",
   "metadata": {},
   "source": [
    "# GPU\n",
    "\n",
    "This lecture was built using [hardware](https://jax.quantecon.org/status.html#status-machine-details) that has access to a GPU.\n",
    "\n",
    "To run this lecture on [Google Colab](https://colab.research.google.com/), click on the “play” icon top right, select Colab, and set the runtime environment to include a GPU.\n",
    "\n",
    "To run this lecture on your own machine, you need to install [Google JAX](https://github.com/google/jax).\n",
    "\n",
    "In addition to what’s in Anaconda, this lecture will need the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cb1af9",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "!pip install quantecon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799ab7dd",
   "metadata": {},
   "source": [
    "We will use the following imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d1c384",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import quantecon as qe\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6615cc8e",
   "metadata": {},
   "source": [
    "Let’s check the GPU we are running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fde8ddd",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aab7e3e",
   "metadata": {},
   "source": [
    "Use 64 bit floats with JAX in order to match NumPy code\n",
    "\n",
    "- By default, JAX uses 32-bit datatypes.  \n",
    "- By default, NumPy uses 64-bit datatypes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7d6141",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "jax.config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4f6d41",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "We consider an optimal savings problem with CRRA utility and budget constraint\n",
    "\n",
    "$$\n",
    "W_{t+1} + C_t \\leq R W_t + Y_t\n",
    "$$\n",
    "\n",
    "We assume that labor income $ (Y_t) $ is a discretized AR(1) process.\n",
    "\n",
    "The right-hand side of the Bellman equation is\n",
    "\n",
    "$$\n",
    "B((w, y), w', v) = u(Rw + y - w') + β \\sum_{y'} v(w', y') Q(y, y').\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "u(c) = \\frac{c^{1-\\gamma}}{1-\\gamma}\n",
    "$$\n",
    "\n",
    "We use successive approximation for VFI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e76c497",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def successive_approx(T,                     # Operator (callable)\n",
    "                      x_0,                   # Initial condition\n",
    "                      tolerance=1e-6,        # Error tolerance\n",
    "                      max_iter=10_000,       # Max iteration bound\n",
    "                      print_step=25,         # Print at multiples\n",
    "                      verbose=False): \n",
    "    x = x_0\n",
    "    error = tolerance + 1\n",
    "    k = 1\n",
    "    while error > tolerance and k <= max_iter:\n",
    "        x_new = T(x)\n",
    "        error = jnp.max(jnp.abs(x_new - x))\n",
    "        if verbose and k % print_step == 0:\n",
    "            print(f\"Completed iteration {k} with error {error}.\")\n",
    "        x = x_new\n",
    "        k += 1\n",
    "    if error > tolerance:\n",
    "        print(f\"Warning: Iteration hit upper bound {max_iter}.\")\n",
    "    elif verbose:\n",
    "        print(f\"Terminated successfully in {k} iterations.\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70d715c",
   "metadata": {},
   "source": [
    "## Model primitives\n",
    "\n",
    "Here’s a `namedtuple` definition for storing parameters and grids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a89228d",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "Model = namedtuple('Model', \n",
    "                    ('β', 'R', 'γ', 'w_grid', 'y_grid', 'Q'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35bb8f5",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def create_consumption_model(R=1.01,                    # Gross interest rate\n",
    "                             β=0.98,                    # Discount factor\n",
    "                             γ=2.5,                     # CRRA parameter\n",
    "                             w_min=0.01,                # Min wealth\n",
    "                             w_max=5.0,                 # Max wealth\n",
    "                             w_size=150,                # Grid side\n",
    "                             ρ=0.9, ν=0.1, y_size=100): # Income parameters\n",
    "    \"\"\"\n",
    "    A function that takes in parameters and returns an instance of Model that\n",
    "    contains data for the optimal savings problem.\n",
    "    \"\"\"\n",
    "    w_grid = jnp.linspace(w_min, w_max, w_size)  \n",
    "    mc = qe.tauchen(n=y_size, rho=ρ, sigma=ν)\n",
    "    y_grid, Q = jnp.exp(mc.state_values), mc.P\n",
    "    return Model(β=β, R=R, γ=γ, w_grid=w_grid, y_grid=y_grid, Q=Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22715ef2",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def create_consumption_model_jax(R=1.01,                    # Gross interest rate\n",
    "                             β=0.98,                    # Discount factor\n",
    "                             γ=2.5,                     # CRRA parameter\n",
    "                             w_min=0.01,                # Min wealth\n",
    "                             w_max=5.0,                 # Max wealth\n",
    "                             w_size=150,                # Grid side\n",
    "                             ρ=0.9, ν=0.1, y_size=100): # Income parameters\n",
    "    \"\"\"\n",
    "    A function that takes in parameters and returns a JAX-compatible version of Model that\n",
    "    contains data for the optimal savings problem.\n",
    "    \"\"\"\n",
    "    w_grid = jnp.linspace(w_min, w_max, w_size)\n",
    "    mc = qe.tauchen(n=y_size, rho=ρ, sigma=ν)\n",
    "    y_grid, Q = jnp.exp(mc.state_values), mc.P\n",
    "    β, R, γ = jax.device_put([β, R, γ])\n",
    "    w_grid, y_grid, Q = tuple(map(jax.device_put, [w_grid, y_grid, Q]))\n",
    "    sizes = w_size, y_size\n",
    "    return (β, R, γ), sizes, (w_grid, y_grid, Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8592e5c6",
   "metadata": {},
   "source": [
    "Here’s the right hand side of the Bellman equation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2828ab3",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def B(v, constants, sizes, arrays):\n",
    "    \"\"\"\n",
    "    A vectorized version of the right-hand side of the Bellman equation \n",
    "    (before maximization), which is a 3D array representing\n",
    "\n",
    "        B(w, y, w′) = u(Rw + y - w′) + β Σ_y′ v(w′, y′) Q(y, y′)\n",
    "\n",
    "    for all (w, y, w′).\n",
    "    \"\"\"\n",
    "\n",
    "    # Unpack \n",
    "    β, R, γ = constants\n",
    "    w_size, y_size = sizes\n",
    "    w_grid, y_grid, Q = arrays\n",
    "\n",
    "    # Compute current rewards r(w, y, wp) as array r[i, j, ip]\n",
    "    w  = jnp.reshape(w_grid, (w_size, 1, 1))    # w[i]   ->  w[i, j, ip]\n",
    "    y  = jnp.reshape(y_grid, (1, y_size, 1))    # z[j]   ->  z[i, j, ip]\n",
    "    wp = jnp.reshape(w_grid, (1, 1, w_size))    # wp[ip] -> wp[i, j, ip]\n",
    "    c = R * w + y - wp\n",
    "\n",
    "    # Calculate continuation rewards at all combinations of (w, y, wp)\n",
    "    v = jnp.reshape(v, (1, 1, w_size, y_size))  # v[ip, jp] -> v[i, j, ip, jp]\n",
    "    Q = jnp.reshape(Q, (1, y_size, 1, y_size))  # Q[j, jp]  -> Q[i, j, ip, jp]\n",
    "    EV = jnp.sum(v * Q, axis=3)                 # sum over last index jp\n",
    "\n",
    "    # Compute the right-hand side of the Bellman equation\n",
    "    return jnp.where(c > 0, c**(1-γ)/(1-γ) + β * EV, -jnp.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc087a7",
   "metadata": {},
   "source": [
    "## Operators\n",
    "\n",
    "Now we define the policy operator $ T_\\sigma $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771d9c85",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def compute_r_σ(σ, constants, sizes, arrays):\n",
    "    \"\"\"\n",
    "    Compute the array r_σ[i, j] = r[i, j, σ[i, j]], which gives current\n",
    "    rewards given policy σ.\n",
    "    \"\"\"\n",
    "\n",
    "    # Unpack model\n",
    "    β, R, γ = constants\n",
    "    w_size, y_size = sizes\n",
    "    w_grid, y_grid, Q = arrays\n",
    "\n",
    "    # Compute r_σ[i, j]\n",
    "    w = jnp.reshape(w_grid, (w_size, 1))\n",
    "    y = jnp.reshape(y_grid, (1, y_size))\n",
    "    wp = w_grid[σ]\n",
    "    c = R * w + y - wp\n",
    "    r_σ = c**(1-γ)/(1-γ)\n",
    "\n",
    "    return r_σ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c058e3c",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def T_σ(v, σ, constants, sizes, arrays):\n",
    "    \"The σ-policy operator.\"\n",
    "\n",
    "    # Unpack model\n",
    "    β, R, γ = constants\n",
    "    w_size, y_size = sizes\n",
    "    w_grid, y_grid, Q = arrays\n",
    "\n",
    "    r_σ = compute_r_σ(σ, constants, sizes, arrays)\n",
    "\n",
    "    # Compute the array v[σ[i, j], jp]\n",
    "    yp_idx = jnp.arange(y_size)\n",
    "    yp_idx = jnp.reshape(yp_idx, (1, 1, y_size))\n",
    "    σ = jnp.reshape(σ, (w_size, y_size, 1))\n",
    "    V = v[σ, yp_idx]      \n",
    "\n",
    "    # Convert Q[j, jp] to Q[i, j, jp] \n",
    "    Q = jnp.reshape(Q, (1, y_size, y_size))\n",
    "\n",
    "    # Calculate the expected sum Σ_jp v[σ[i, j], jp] * Q[i, j, jp]\n",
    "    Ev = jnp.sum(V * Q, axis=2)\n",
    "\n",
    "    return r_σ + β * jnp.sum(V * Q, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735d1d43",
   "metadata": {},
   "source": [
    "and the Bellman operator $ T $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041b8dde",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def T(v, constants, sizes, arrays):\n",
    "    \"The Bellman operator.\"\n",
    "    return jnp.max(B(v, constants, sizes, arrays), axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51dfdbb",
   "metadata": {},
   "source": [
    "The next function computes a $ v $-greedy policy given $ v $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aaf159",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def get_greedy(v, constants, sizes, arrays):\n",
    "    \"Computes a v-greedy policy, returned as a set of indices.\"\n",
    "    return jnp.argmax(B(v, constants, sizes, arrays), axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da43874",
   "metadata": {},
   "source": [
    "The function below computes the value $ v_\\sigma $ of following policy $ \\sigma $.\n",
    "\n",
    "The basic problem is to solve the linear system\n",
    "\n",
    "$$\n",
    "v(w,y ) = u(Rw + y - \\sigma(w, y)) + β \\sum_{y'} v(\\sigma(w, y), y') Q(y, y)\n",
    "$$\n",
    "\n",
    "for $ v $.\n",
    "\n",
    "It turns out to be helpful to rewrite this as\n",
    "\n",
    "$$\n",
    "v(w,y) = r(w, y, \\sigma(w, y)) + β \\sum_{w', y'} v(w', y') P_\\sigma(w, y, w', y')\n",
    "$$\n",
    "\n",
    "where $ P_\\sigma(w, y, w', y') = 1\\{w' = \\sigma(w, y)\\} Q(y, y') $.\n",
    "\n",
    "We want to write this as $ v = r_\\sigma + P_\\sigma v $ and then solve for $ v $\n",
    "\n",
    "Note, however,\n",
    "\n",
    "- $ v $ is a 2 index array, rather than a single vector.  \n",
    "- $ P_\\sigma $ has four indices rather than 2  \n",
    "\n",
    "\n",
    "The code below\n",
    "\n",
    "1. reshapes $ v $ and $ r_\\sigma $ to 1D arrays and $ P_\\sigma $ to a matrix  \n",
    "1. solves the linear system  \n",
    "1. converts back to multi-index arrays.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2270ef1c",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def get_value(σ, constants, sizes, arrays):\n",
    "    \"Get the value v_σ of policy σ by inverting the linear map R_σ.\"\n",
    "\n",
    "    # Unpack \n",
    "    β, R, γ = constants\n",
    "    w_size, y_size = sizes\n",
    "    w_grid, y_grid, Q = arrays\n",
    "\n",
    "    r_σ = compute_r_σ(σ, constants, sizes, arrays)\n",
    "\n",
    "    # Reduce R_σ to a function in v\n",
    "    partial_R_σ = lambda v: R_σ(v, σ, constants, sizes, arrays)\n",
    "\n",
    "    return jax.scipy.sparse.linalg.bicgstab(partial_R_σ, r_σ)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5f2db7",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def R_σ(v, σ, constants, sizes, arrays):\n",
    "    \"\"\"\n",
    "    The value v_σ of a policy σ is defined as \n",
    "\n",
    "        v_σ = (I - β P_σ)^{-1} r_σ\n",
    "\n",
    "    Here we set up the linear map v -> R_σ v, where R_σ := I - β P_σ. \n",
    "\n",
    "    In the consumption problem, this map can be expressed as\n",
    "\n",
    "        (R_σ v)(w, y) = v(w, y) - β Σ_y′ v(σ(w, y), y′) Q(y, y′)\n",
    "\n",
    "    Defining the map as above works in a more intuitive multi-index setting\n",
    "    (e.g. working with v[i, j] rather than flattening v to a one-dimensional\n",
    "    array) and avoids instantiating the large matrix P_σ.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    β, R, γ = constants\n",
    "    w_size, y_size = sizes\n",
    "    w_grid, y_grid, Q = arrays\n",
    "\n",
    "    # Set up the array v[σ[i, j], jp]\n",
    "    zp_idx = jnp.arange(y_size)\n",
    "    zp_idx = jnp.reshape(zp_idx, (1, 1, y_size))\n",
    "    σ = jnp.reshape(σ, (w_size, y_size, 1))\n",
    "    V = v[σ, zp_idx]\n",
    "\n",
    "    # Expand Q[j, jp] to Q[i, j, jp]\n",
    "    Q = jnp.reshape(Q, (1, y_size, y_size))\n",
    "\n",
    "    # Compute and return v[i, j] - β Σ_jp v[σ[i, j], jp] * Q[j, jp]\n",
    "    return v - β * jnp.sum(V * Q, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20d5718",
   "metadata": {},
   "source": [
    "## JIT compiled versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ccf542",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "B = jax.jit(B, static_argnums=(2,))\n",
    "compute_r_σ = jax.jit(compute_r_σ, static_argnums=(2,))\n",
    "T = jax.jit(T, static_argnums=(2,))\n",
    "get_greedy = jax.jit(get_greedy, static_argnums=(2,))\n",
    "get_value = jax.jit(get_value, static_argnums=(2,))\n",
    "T_σ = jax.jit(T_σ, static_argnums=(3,))\n",
    "R_σ = jax.jit(R_σ, static_argnums=(3,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f62f0d3",
   "metadata": {},
   "source": [
    "## Solvers\n",
    "\n",
    "Now we define the solvers, which implement VFI, HPI and OPI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548cd93e",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def value_iteration(model, tol=1e-5):\n",
    "    \"Implements VFI.\"\n",
    "\n",
    "    constants, sizes, arrays = model\n",
    "    _T = lambda v: T(v, constants, sizes, arrays)\n",
    "    vz = jnp.zeros(sizes)\n",
    "\n",
    "    v_star = successive_approx(_T, vz, tolerance=tol)\n",
    "    return get_greedy(v_star, constants, sizes, arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1242a67",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def policy_iteration(model):\n",
    "    \"Howard policy iteration routine.\"\n",
    "    constants, sizes, arrays = model\n",
    "    vz = jnp.zeros(sizes)\n",
    "    σ = jnp.zeros(sizes, dtype=int)\n",
    "    i, error = 0, 1.0\n",
    "    while error > 0:\n",
    "        v_σ = get_value(σ, constants, sizes, arrays)\n",
    "        σ_new = get_greedy(v_σ, constants, sizes, arrays)\n",
    "        error = jnp.max(jnp.abs(σ_new - σ))\n",
    "        σ = σ_new\n",
    "        i = i + 1\n",
    "        print(f\"Concluded loop {i} with error {error}.\")\n",
    "    return σ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239de451",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def optimistic_policy_iteration(model, tol=1e-5, m=10):\n",
    "    \"Implements the OPI routine.\"\n",
    "    constants, sizes, arrays = model\n",
    "    v = jnp.zeros(sizes)\n",
    "    error = tol + 1\n",
    "    while error > tol:\n",
    "        last_v = v\n",
    "        σ = get_greedy(v, constants, sizes, arrays)\n",
    "        for _ in range(m):\n",
    "            v = T_σ(v, σ, constants, sizes, arrays)\n",
    "        error = jnp.max(jnp.abs(v - last_v))\n",
    "    return get_greedy(v, constants, sizes, arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a315f0",
   "metadata": {},
   "source": [
    "## Plots\n",
    "\n",
    "Create a JAX model for consumption, perform policy iteration, and plot the resulting optimal policy function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caa9880",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "fontsize=12\n",
    "model = create_consumption_model_jax()\n",
    "# Unpack \n",
    "constants, sizes, arrays = model\n",
    "β, R, γ = constants\n",
    "w_size, y_size = sizes\n",
    "w_grid, y_grid, Q = arrays\n",
    "σ_star = policy_iteration(model)\n",
    "fig, ax = plt.subplots(figsize=(9, 5.2))\n",
    "ax.plot(w_grid, w_grid, \"k--\", label=\"45\")\n",
    "ax.plot(w_grid, w_grid[σ_star[:, 1]], label=\"$\\\\sigma^*(\\cdot, y_1)$\")\n",
    "ax.plot(w_grid, w_grid[σ_star[:, -1]], label=\"$\\\\sigma^*(\\cdot, y_N)$\")\n",
    "ax.legend(fontsize=fontsize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488b3289",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "Here’s a quick test of the timing of each solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1442375d",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "model = create_consumption_model_jax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f65d51",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "print(\"Starting HPI.\")\n",
    "start_time = time.time()\n",
    "out = policy_iteration(model)\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"HPI completed in {elapsed} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6d20af",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "print(\"Starting VFI.\")\n",
    "start_time = time.time()\n",
    "out = value_iteration(model)\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"VFI(jax not in succ) completed in {elapsed} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab63ff4c",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "print(\"Starting OPI.\")\n",
    "start_time = time.time()\n",
    "out = optimistic_policy_iteration(model, m=100)\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"OPI completed in {elapsed} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e420c24d",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def run_algorithm(algorithm, model, **kwargs):\n",
    "    start_time = time.time()\n",
    "    result = algorithm(model, **kwargs)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"{algorithm.__name__} completed in {elapsed_time:.2f} seconds.\")\n",
    "    return result, elapsed_time\n",
    "\n",
    "model = create_consumption_model_jax()\n",
    "σ_pi, pi_time = run_algorithm(policy_iteration, model)\n",
    "σ_vfi, vfi_time = run_algorithm(value_iteration, model, tol=1e-5)\n",
    "\n",
    "m_vals = range(5, 3000, 100)\n",
    "opi_times = []\n",
    "for m in m_vals:\n",
    "    σ_opi, opi_time = run_algorithm(optimistic_policy_iteration, model, m=m, tol=1e-5)\n",
    "    opi_times.append(opi_time)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 5.2))\n",
    "ax.plot(m_vals, jnp.full(len(m_vals), pi_time), lw=2, label=\"Howard policy iteration\")\n",
    "ax.plot(m_vals, jnp.full(len(m_vals), vfi_time), lw=2, label=\"value function iteration\")\n",
    "ax.plot(m_vals, opi_times, lw=2, label=\"optimistic policy iteration\")\n",
    "ax.legend(fontsize=fontsize, frameon=False)\n",
    "ax.set_xlabel(\"$m$\", fontsize=fontsize)\n",
    "ax.set_ylabel(\"time\", fontsize=fontsize)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "date": 1684405498.6149373,
  "filename": "opt_savings.md",
  "kernelspec": {
   "display_name": "Python",
   "language": "python3",
   "name": "python3"
  },
  "title": "Optimal Savings"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}