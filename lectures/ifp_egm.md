---
jupytext:
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.14.5
kernelspec:
  display_name: Python 3 (ipykernel)
  language: python
  name: python3
---

# Endogenous Grid Method


```{include} _admonition/gpu.md
```

## Overview

In this lecture we use the endogenous grid method to solve a basic income
fluctuation (optimal savings) problem.

Some general backgroud on The endogeous grid method can be found in [an earlier
QuantEcon lecture](https://python.quantecon.org/egm_policy_iter.html).

Here we focus on providing an efficient JAX implmentation.

We will use the following libraries and imports.

```{code-cell}
:tags: [hide-output]

!pip install --upgrade quantecon interpolation
```

```{code-cell}
import quantecon as qe
import matplotlib.pyplot as plt
import numpy as np
import jax
import jax.numpy as jnp

from interpolation import interp
from numba import njit, float64
from numba.experimental import jitclass
```

We use 64 bit floating point numbers for extra precision.

```{code-cell}
jax.config.update("jax_enable_x64", True)
```

## Setup 

We consider a household that chooses a state-contingent consumption plan $\{c_t\}_{t \geq 0}$ to maximize

$$
\mathbb{E} \, \sum_{t=0}^{\infty} \beta^t u(c_t)
$$

subject to

$$
    a_{t+1} \leq  R(a_t - c_t)  + Y_{t+1},
    \quad c_t \geq 0,
    \quad a_t \geq 0
    \quad t = 0, 1, \ldots
$$

Here $R = 1 + r$ where $r$ is the interest rate.

The income process $\{Y_t\}$ is a [Markov chain](https://python.quantecon.org/finite_markov.html) generated by stochastic matrix $P$.

The matrix $P$ and the grid of values taken by $Y_t$ are obtained by
discretizing the AR(1) process

$$
    Y_{t+1} = \rho Y_t + \nu \epsilon_{t+1}
$$

where $\{\epsilon_t\}$ is IID and standard normal.

Utility has the CRRA specification

$$
    u(c) = \frac{c^{1 - \gamma}} {1 - \gamma}
$$


The following function stores default parameter values for the income
fluctuation problem and creates suitable arrays.

```{code-cell}
def ifp(R=1.01,             # gross interest rate
        β=0.96,             # discount factor
        γ=1.5,              # CRRA preference parameter
        grid_max=16,        # asset grid max
        grid_size=200,      # asset grid size
        ρ=0.99,             # income persistence
        ν=0.02,             # income volatility
        y_size=25):         # income grid size
  
    # Create income Markov chain
    mc = qe.tauchen(y_size, ρ, ν)
    y_grid, P = jnp.exp(mc.state_values), mc.P
    # Shift to JAX arrays
    P, y_grid = jax.device_put((P, y_grid))
    
    a_grid = jnp.linspace(0, grid_max, grid_size)
    sizes = grid_size, y_size
    a_grid, y_grid, P = jax.device_put((a_grid, y_grid, P))

    # require R β < 1 for convergence
    assert R * β < 1, "Stability condition violated."
        
    return (β, R, γ), sizes, (a_grid, y_grid, P)

# ## Solution method
#
# Let $S = \RR_+ \times \mathsf Y$ be the set of possible values for the state $(a_t, Y_t)$.
#
# We aim to compute an optimal consumption policy $\sigma^* \colon S \to \mathbb R$, under which 
#
# $$
#     (a_0, z_0) = (a, z),
#     \quad
#     c_t = \sigma^*(a_t, Z_t)
#     \quad \text{and} \quad
#     a_{t+1} = R (a_t - c_t) + Y_{t+1}
# $$
#
#
# In this section we discuss how we intend to solve for this policy.
#
#
# ### Euler equation
#
# The Euler equation for the optimization problem is
#
# $$
#     u' (c_t)
#     = \max \left\{
#         \beta R \,  \mathbb{E}_t  u'(c_{t+1})  \,,\;  u'(a_t)
#     \right\}
# $$
#
# An explanation for this expression can be found [here](https://python.quantecon.org/ifp.html#value-function-and-euler-equation).
#
# We rewrite the Euler equation in functional form
#
# $$
#     (u' \circ \sigma)  (a, z)
#     = \max \left\{
#     \beta R \, \mathbb E_z (u' \circ \sigma)
#         [R (a - \sigma(a, z)) + \hat Y, \, \hat Z]
#     \, , \;
#          u'(a)
#          \right\}
# $$
#
#
# where $(u' \circ \sigma)(s) := u'(\sigma(s))$.
#
# Let $\mathscr C$ be the space of continuous functions $\sigma \colon \mathbf S
# \to \mathbb R$ such that $\sigma$ is increasing in the first argument, $0 <
# \sigma(a,z) \leq a$ for all $(a,z) \in \mathbf S$, and
#
# $$
#     \sup_{(a,z) \in \mathbf S}
#     \left| (u' \circ \sigma)(a,z) - u'(a) \right| < \infty
# $$
#
# For given $\sigma \in \mathscr{C}$, define $K \sigma (a,z)$ as the unique $c \in [0, a]$ that solves
#
# $$
# u'(c)
# = \max \left\{
#            \beta R \, \mathbb E_z (u' \circ \sigma) \,
#            [R (a - c) + \hat Y, \, \hat Z]
#            \, , \;
#            u'(a)
#      \right\}
# $$ (eq:kaper)
#
# We call $K$ is the [Coleman--Reffett operator](https://python.quantecon.org/ifp.html#computation).
#
# The EGM is to take a grid of saving values $s_i=a_i - c_i$.
#
# $$
# c
# = (u')^{-1}\left (\max \left\{
#            \beta R \, \mathbb E_z (u' \circ \sigma) \,
#            [R (a - c) + \hat Y, \, \hat Z]
#            \, , \;
#            u'(a)
#      \right\} \right )
# $$

# On one hand, $a_0=s_0=0$.
#
# On the other hand since $s>0$ implies $c<a$ consumption is interior.
#
# Hence we can drop out the max and we solve for 
#
# $$
# c_i =
# (u')^{-1}
# \left\{
#     \beta \, R \mathbb E_z
#     (u' \circ \sigma) \, [\hat R s_i + \hat Y, \, \hat Z]
# \right\}
# $$ (euler)
#
# for each $s_i$.
#
# Reference: https://python.quantecon.org/ifp_advanced.html#using-an-endogenous-grid
#
#
# ### Jax version 
#
# First we define a vectorized operator $K$ based on {eq}`kaper`.

def K_egm(a_in, σ_in, constants, sizes, arrays):
    """
    The vectorzied operator K using EGM.

    """
    
    # Unpack
    β, R, γ = constants
    grid_size, y_size = sizes
    grid, y_grid, P = arrays
    
    def u_prime(c):
        return c**(-γ)

    def u_prime_inv(u_prime):
            return u_prime**(-1/γ)


    # Linearly interpolate σ(a, z)
    def σ(a, z):
        return jnp.interp(a, a_in[:,z], σ_in[:,z])

    σ_vec = jnp.vectorize(σ)

    
    # Broadcast and vectorize
    z_grid = jnp.reshape(jnp.arange(y_size), (1, y_size, 1))
    z_hat_grid = jnp.reshape(jnp.arange(y_size), (1, 1, y_size))
    s_grid = jnp.reshape(grid, (grid_size, 1, 1))
    
    # Evaluate σ_out
    a_next = R * s_grid + y_grid[z_hat_grid]
    σ_next = σ_vec(a_next, z_hat_grid)
    up = u_prime(σ_next)
    P = jnp.reshape(P, (1, y_size, y_size))
    E = jnp.sum(up * P, axis=-1)

    σ_out = u_prime_inv(β * R * E)

    # Compute a_out by s = a - c
    a_out = grid[:, jnp.newaxis] + σ_out
    
    # Set σ_0 = 0 and a_0 = 0
    σ_out = σ_out.at[0, :].set(0)
    a_out = a_out.at[0, :].set(0)

    return a_out, σ_out

# Then we use ``jax.jit`` to compile the vectorized $K$.

K_egm_jax = jax.jit(K_egm, static_argnums=(3,))


# Next we define a successive approximator that repeatedly applies $K$.

def successive_approx_jax(model,        
            tol=1e-5,
            max_iter=1000,
            verbose=True,
            print_skip=25):

    # Unpack
    constants, sizes, arrays = model
    
    β, R, γ = constants
    grid_size, y_size = sizes
    grid, y_grid, P = arrays
    
    # Set up loop
    σ_init = jnp.tile(grid, [y_size, 1]).T
    a_init = jnp.copy(σ_init)
    a_vec, σ_vec = a_init, σ_init
    
    i = 0
    error = tol + 1

    while i < max_iter and error > tol:
        a_new, σ_new = K_egm_jax(a_vec, σ_vec, constants, sizes, arrays)    
        error = jnp.max(jnp.abs(σ_vec - σ_new))
        i += 1
        if verbose and i % print_skip == 0:
            print(f"Error at iteration {i} is {error}.")
        a_vec, σ_vec = jnp.copy(a_new), jnp.copy(σ_new)

    if error > tol:
        print("Failed to converge!")
    elif verbose:
        print(f"\nConverged in {i} iterations.")

    return a_new, σ_new


# ### Numba version 
#
# Below we provide a second set of code, which solves the same model with Numba.
#
# The purpose of this code is to cross-check our results from the JAX version, as
# well as to do a runtime comparison.
#
# Most readers will want to skip ahead to the next section, where we solve the
# model and run the cross-check.
```

```{code-cell}
ifp_data = [
    ('R', float64),              
    ('β', float64),             
    ('γ', float64),            
    ('P', float64[:, :]),     
    ('y_grid', float64[:]),  
    ('grid', float64[:])    
]

model = ifp()
constants, sizes, arrays = model
β, R, γ = constants
grid_size, y_size = sizes
grid, y_grid, P = (np.array(a) for a in arrays)

@jitclass(ifp_data)
class IFP:

    def __init__(self,
                 R=R,
                 β=β,
                 γ=γ,
                 P=np.array(P),
                 y_grid=np.array(y_grid),
                 grid=grid):

        self.R, self.β, self.γ = R, β, γ
        self.P, self.y_grid = P, y_grid
        self.grid = grid

        # Recall that we need R β < 1 for convergence.
        assert self.R * self.β < 1, "Stability condition violated."

    def u_prime(self, c):
        return c**(-self.γ)
    
    def u_prime_inv(self, u_prime):
        return u_prime**(-1/self.γ)
```

```{code-cell}
@njit
def K_egm_nb(a_in, σ_in, ifp):
    """
    The operator K using Numba.

    """
    
    # Simplify names
    R, P, y_grid, β, γ  = ifp.R, ifp.P, ifp.y_grid, ifp.β, ifp.γ
    grid, u_prime = ifp.grid, ifp.u_prime
    u_prime_inv = ifp.u_prime_inv
    n = len(y_grid)
    
    
    # Linear interpolation of policy using endogenous grid
    def σ(a, z):
        return interp(a_in[:, z], σ_in[:, z], a)
    
    
    # Allocate memory for new consumption array
    σ_out = np.empty_like(σ_in)
    
    for i, s in enumerate(grid):
        for z in range(n):
            expect = 0.0
            for z_hat in range(n):
                expect += u_prime(σ(R * s + y_grid[z_hat], z_hat)) * P[z, z_hat]

            σ_out[i, z] = u_prime_inv(β * R * expect)
    
    # Calculate endogenous asset grid
    a_out = np.empty_like(σ_out)
    for z in range(n):
        a_out[:, z] = grid + σ_out[:, z]

    # Fixing a consumption-asset pair at (0, 0) improves interpolation
    σ_out[0, :] = 0
    a_out[0, :] = 0
    
    return a_out, σ_out
```

```{code-cell}
def successive_approx_numba(model,        # Class with model information
              tol=1e-5,
              max_iter=1000,
              verbose=True,
              print_skip=25):

    # Unpack
    P, grid = model.P, model.grid
    n = len(P)
    
    σ_init = np.tile(grid, (n, 1)).T
    a_init = np.copy(σ_init)
    a_vec, σ_vec = a_init, σ_init
    
    # Set up loop
    i = 0
    error = tol + 1

    while i < max_iter and error > tol:
        a_new, σ_new = K_egm_nb(a_vec, σ_vec, model)
        error = np.max(np.abs(σ_vec - σ_new))
        i += 1
        if verbose and i % print_skip == 0:
            print(f"Error at iteration {i} is {error}.")
        a_vec, σ_vec = np.copy(a_new), np.copy(σ_new)

    if error > tol:
        print("Failed to converge!")
    elif verbose:
        print(f"\nConverged in {i} iterations.")

    return a_new, σ_new
```

## Solutions

First we solve the IFP with JAX.

```{code-cell}
ifp_jax = ifp()
```

Here's a first run.

```{code-cell}
qe.tic()
a_star_egm_jax, σ_star_egm_jax = successive_approx_jax(ifp_jax,
                                         print_skip=5)
qe.toc()
```

Let's run again so we can see the run time without compilation.

```{code-cell}
qe.tic()
a_star_egm_jax, σ_star_egm_jax = successive_approx_jax(ifp_jax,
                                         print_skip=5)
jax_time = qe.toc()
```

Next let's solve the same IFP with Numba.

```{code-cell}
ifp_numba = IFP()
```

```{code-cell}
qe.tic()
a_star_egm_nb, σ_star_egm_nb = successive_approx_numba(ifp_numba,
                                         print_skip=5)
qe.toc()
```

Let's run again so we can see the run time without compilation.

```{code-cell}
qe.tic()
a_star_egm_nb, σ_star_egm_nb = successive_approx_numba(ifp_numba,
                                         print_skip=5)
numba_time = qe.toc()
```

The JAX code is significantly faster, as expected.

This difference will increase when more features (and state variables) are added
to the model.

Lastly, let's plot the consumption functions for a sanity check.

```{code-cell}
fig, ax = plt.subplots()

n = len(ifp_numba.P)
for z in (0, y_size-1):
    ax.plot(a_star_egm_nb[:, z], 
            σ_star_egm_nb[:, z], 
            '--', lw=2,
            label=f"Numba EGM: consumption when $z={z}$")
    ax.plot(a_star_egm_jax[:, z], 
            σ_star_egm_jax[:, z], 
            label=f"JAX EGM: consumption when $z={z}$")

ax.set_xlabel('asset')
plt.legend()
plt.show()
```
