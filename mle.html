

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>8. Maximum Likelihood Estimation &#8212; Quantitative Economics with Python using JAX</title>
    <script src="https://unpkg.com/@popperjs/core@2.9.2/dist/umd/popper.min.js"></script>
    <script src="https://unpkg.com/tippy.js@6.3.1/dist/tippy-bundle.umd.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js"></script>
    
        <script>
            MathJax = {
            loader: {load: ['[tex]/boldsymbol', '[tex]/textmacros']},
            tex: {
                packages: {'[+]': ['boldsymbol', 'textmacros']},
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                processEscapes: true,
                macros: {
                    "argmax" : "arg\\,max",
                    "argmin" : "arg\\,min",
                    "col"    : "col",
                    "Span"   :  "span",
                    "epsilon": "\\varepsilon",
                    "EE": "\\mathbb{E}",
                    "PP": "\\mathbb{P}",
                    "RR": "\\mathbb{R}",
                    "NN": "\\mathbb{N}",
                    "ZZ": "\\mathbb{Z}",
                    "aA": "\\mathcal{A}",
                    "bB": "\\mathcal{B}",
                    "cC": "\\mathcal{C}",
                    "dD": "\\mathcal{D}",
                    "eE": "\\mathcal{E}",
                    "fF": "\\mathcal{F}",
                    "gG": "\\mathcal{G}",
                    "hH": "\\mathcal{H}",
                }
            },
            svg: {
                fontCache: 'global',
                scale: 0.92,
                displayAlign: "center",
            },
            };
        </script>
    
    
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/quantecon-book-theme.531cac136e77cfd0e9b23b36a70b130a.css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/exercise.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />


    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script src="_static/quantecon-book-theme.282f51e609929a8ffbc5260c6713b9cc.js"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-K1NYBSC1CZ"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-K1NYBSC1CZ');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"tex": {"macros": {"argmax": "arg\\,max", "argmin": "arg\\,min"}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'mle';</script>
    <link rel="canonical" href="https://jax.quantecon.org/mle.html" />
    <link rel="shortcut icon" href="_static/lectures-favicon.ico"/>
    <link rel="author" title="About these documents" href="about.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="9. Shortest Paths" href="short_path.html" />
    <link rel="prev" title="7. Wealth Distribution Dynamics" href="wealth_dynamics.html" />

<!-- Normal Meta Tags -->
<meta name="author" context="Thomas J. Sargent &amp; John Stachurski" />
<meta name="keywords" content="Python, QuantEcon, Quantitative Economics, Economics, Sloan, Alfred P. Sloan Foundation, Tom J. Sargent, John Stachurski" />
<meta name="description" content=This website presents a set of lectures on quantitative economic modeling, designed and written by Thomas J. Sargent and John Stachurski. />

<!-- Twitter tags -->
<meta name="twitter:card" content="summary" />
<meta name="twitter:site" content="@quantecon" />
<meta name="twitter:title" content="Maximum Likelihood Estimation"/>
<meta name="twitter:description" content="This website presents a set of lectures on quantitative economic modeling, designed and written by Thomas J. Sargent and John Stachurski.">
<meta name="twitter:creator" content="@quantecon">
<meta name="twitter:image" content="https://assets.quantecon.org/img/qe-twitter-logo.png">

<!-- Opengraph tags -->
<meta property="og:title" content="Maximum Likelihood Estimation" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://jax.quantecon.org/mle.html" />
<meta property="og:image" content="https://assets.quantecon.org/img/qe-og-logo.png" />
<meta property="og:description" content="This website presents a set of lectures on quantitative economic modeling, designed and written by Thomas J. Sargent and John Stachurski." />
<meta property="og:site_name" content="Quantitative Economics with Python using JAX" />
<meta name="theme-color" content="#ffffff" />

  </head>
<body>


    <span id="top"></span>

    <div class="qe-wrapper">

        <div class="qe-main">

            <div class="qe-page" id=mle>

                <div class="qe-page__toc">

                    <div class="inner">

                        
                        <div class="qe-page__toc-header">
                            On this page
                        </div>


                        <nav id="bd-toc-nav" class="qe-page__toc-nav">
                            <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">8.1. Overview</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mle-with-numerical-methods-jax">8.2. MLE with numerical methods (JAX)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-toy-model">8.2.1. A toy model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-poisson-model">8.2.2. A Poisson model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#mle-with-statsmodels">8.3. MLE with <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code></a></li>
</ul>
                            <p class="logo">
                                
                                    
                                    <a href=https://quantecon.org><img src="_static/qe-logo-large.png" class="logo" alt="logo"></a>
                                    
                                
                            </p>

                            <p class="powered">Powered by <a href="https://jupyterbook.org/">Jupyter Book</a></p>

                        </nav>

                        <div class="qe-page__toc-footer">
                            
                            
                            <p><a href="#top"><strong>Back to top</strong></a></p>
                        </div>

                    </div>

                </div>

                <div class="qe-page__header">

                    <div class="qe-page__header-copy">

                        <p class="qe-page__header-heading"><a href="intro.html">Quantitative Economics with Python using JAX</a></p>

                        <p class="qe-page__header-subheading">Maximum Likelihood Estimation</p>

                    </div>

                    <p class="qe-page__header-authors">Thomas J. Sargent & John Stachurski</p>

                </div> <!-- .page__header -->



                
                <main class="qe-page__content" role="main">
                    
                    <div>
                        
  <section class="tex2jax_ignore mathjax_ignore" id="maximum-likelihood-estimation">
<h1><a class="toc-backref" href="#id1"><span class="section-number">8. </span>Maximum Likelihood Estimation</a><a class="headerlink" href="#maximum-likelihood-estimation" title="Permalink to this heading">#</a></h1>
<div class="contents topic" id="contents">
<p class="topic-title">Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#maximum-likelihood-estimation" id="id1">Maximum Likelihood Estimation</a></p>
<ul>
<li><p><a class="reference internal" href="#overview" id="id2">Overview</a></p></li>
<li><p><a class="reference internal" href="#mle-with-numerical-methods-jax" id="id3">MLE with numerical methods (JAX)</a></p></li>
<li><p><a class="reference internal" href="#mle-with-statsmodels" id="id4">MLE with <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code></a></p></li>
</ul>
</li>
</ul>
</div>
<div class="warning admonition">
<p class="admonition-title">GPU</p>
<p>This lecture was built using <a class="reference internal" href="status.html#status-machine-details"><span class="std std-ref">hardware</span></a> that has access to a GPU.</p>
<p>To run this lecture on <a class="reference external" href="https://colab.research.google.com/">Google Colab</a>, click on the “play” icon top right, select Colab, and set the runtime environment to include a GPU.</p>
<p>To run this lecture on your own machine, you need to install <a class="reference external" href="https://github.com/google/jax">Google JAX</a>.</p>
</div>
<section id="overview">
<h2><a class="toc-backref" href="#id2"><span class="section-number">8.1. </span>Overview</a><a class="headerlink" href="#overview" title="Permalink to this heading">#</a></h2>
<p>This lecture is the extended JAX implementation of <a class="reference external" href="https://python.quantecon.org/mle.html#mle-with-numerical-methods">this section</a> of <a class="reference external" href="https://python.quantecon.org/mle.html">this lecture</a>.</p>
<p>Please refer that lecture for all background and notation.</p>
<p>Here we will exploit the automatic differentiation capabilities of JAX rather than calculating derivatives by hand.</p>
<p>We’ll require the following imports:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">namedtuple</span>
<span class="kn">import</span> <span class="nn">jax.numpy</span> <span class="k">as</span> <span class="nn">jnp</span>
<span class="kn">import</span> <span class="nn">jax</span>
<span class="kn">from</span> <span class="nn">statsmodels.api</span> <span class="kn">import</span> <span class="n">Poisson</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s check the GPU we are running</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>nvidia-smi
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mon Sep 11 00:25:03 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.182.03   Driver Version: 470.182.03   CUDA Version: 12.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>|   0  Tesla V100-SXM2...  Off  | 00000000:00:1E.0 Off |                    0 |
| N/A   42C    P0    39W / 300W |      0MiB / 16160MiB |      2%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
</pre></div>
</div>
</div>
</div>
<p>We will use 64 bit floats with JAX in order to increase the precision.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">jax</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="s2">&quot;jax_enable_x64&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="mle-with-numerical-methods-jax">
<h2><a class="toc-backref" href="#id3"><span class="section-number">8.2. </span>MLE with numerical methods (JAX)</a><a class="headerlink" href="#mle-with-numerical-methods-jax" title="Permalink to this heading">#</a></h2>
<p>Many distributions do not have nice, analytical solutions and therefore require
numerical methods to solve for parameter estimates.</p>
<p>One such numerical method is the Newton-Raphson algorithm.</p>
<p>Let’s start with a simple example to illustrate the algorithm.</p>
<section id="a-toy-model">
<h3><span class="section-number">8.2.1. </span>A toy model<a class="headerlink" href="#a-toy-model" title="Permalink to this heading">#</a></h3>
<p>Our goal is to find the maximum likelihood estimate <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\beta}}\)</span>.</p>
<p>At <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\beta}}\)</span>, the first derivative of the log-likelihood
function will be equal to 0.</p>
<p>Let’s illustrate this by supposing</p>
<div class="math notranslate nohighlight">
\[
\log \mathcal{L(\beta)} = - (\beta - 10) ^2 - 10
\]</div>
<p>Define the function <code class="docutils literal notranslate"><span class="pre">logL</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@jax</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span> <span class="nf">logL</span><span class="p">(</span><span class="n">β</span><span class="p">):</span>
    <span class="k">return</span> <span class="o">-</span><span class="p">(</span><span class="n">β</span> <span class="o">-</span> <span class="mi">10</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">-</span> <span class="mi">10</span>
</pre></div>
</div>
</div>
</div>
<p>To find the value of <span class="math notranslate nohighlight">\(\frac{d \log \mathcal{L(\boldsymbol{\beta})}}{d \boldsymbol{\beta}}\)</span>, we can use <a class="reference external" href="https://jax.readthedocs.io/en/latest/_autosummary/jax.grad.html">jax.grad</a> which auto-differentiates the given function.</p>
<p>We further use <a class="reference external" href="https://jax.readthedocs.io/en/latest/_autosummary/jax.vmap.html">jax.vmap</a> which vectorizes the given function i.e. the function acting upon scalar inputs can now be used with vector inputs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dlogL</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">logL</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">β</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">β</span><span class="p">,</span> <span class="n">logL</span><span class="p">(</span><span class="n">β</span><span class="p">),</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">β</span><span class="p">,</span> <span class="n">dlogL</span><span class="p">(</span><span class="n">β</span><span class="p">),</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$log \mathcal{L(\beta)}$&#39;</span><span class="p">,</span>
               <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
               <span class="n">labelpad</span><span class="o">=</span><span class="mi">35</span><span class="p">,</span>
               <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\frac{dlog \mathcal{L(\beta)}}{d \beta}$ &#39;</span><span class="p">,</span>
               <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
               <span class="n">labelpad</span><span class="o">=</span><span class="mi">35</span><span class="p">,</span>
               <span class="n">fontsize</span><span class="o">=</span><span class="mi">19</span><span class="p">)</span>

<span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\beta$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">grid</span><span class="p">(),</span> <span class="n">ax2</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">c</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<a class="reference internal image-reference" href="_images/7fe82f23af652549073daeee09939a3add2313a55e9e91c965b41c92e3edcc2a.png"><img alt="_images/7fe82f23af652549073daeee09939a3add2313a55e9e91c965b41c92e3edcc2a.png" src="_images/7fe82f23af652549073daeee09939a3add2313a55e9e91c965b41c92e3edcc2a.png" style="width: 80%;" /></a>
</div>
</div>
<p>The plot shows that the maximum likelihood value (the top plot) occurs
when <span class="math notranslate nohighlight">\(\frac{d \log \mathcal{L(\boldsymbol{\beta})}}{d \boldsymbol{\beta}} = 0\)</span> (the bottom
plot).</p>
<p>Therefore, the likelihood is maximized when <span class="math notranslate nohighlight">\(\beta = 10\)</span>.</p>
<p>We can also ensure that this value is a <em>maximum</em> (as opposed to a
minimum) by checking that the second derivative (slope of the bottom
plot) is negative.</p>
<p>The Newton-Raphson algorithm finds a point where the first derivative is
0.</p>
<p>To use the algorithm, we take an initial guess at the maximum value,
<span class="math notranslate nohighlight">\(\beta_0\)</span> (the OLS parameter estimates might be a reasonable
guess).</p>
<p>Then we use the updating rule involving gradient information to iterate the algorithm until the error is sufficiently small or the algorithm reaches the maximum number of iterations.</p>
<p>Please refer to <a class="reference external" href="https://python.quantecon.org/mle.html#mle-with-numerical-methods">this section</a> for the detailed algorithm.</p>
</section>
<section id="a-poisson-model">
<h3><span class="section-number">8.2.2. </span>A Poisson model<a class="headerlink" href="#a-poisson-model" title="Permalink to this heading">#</a></h3>
<p>Let’s have a go at implementing the Newton-Raphson algorithm to calculate the maximum likelihood estimations of a Poisson  regression.</p>
<p>The Poisson regression has a joint pmf:</p>
<div class="math notranslate nohighlight">
\[
f(y_1, y_2, \ldots, y_n \mid \mathbf{x}_1, \mathbf{x}_2, \ldots, \mathbf{x}_n; \boldsymbol{\beta})
    = \prod_{i=1}^{n} \frac{\mu_i^{y_i}}{y_i!} e^{-\mu_i}\]</div>
<div class="math notranslate nohighlight">
\[
\text{where}\ \mu_i
     = \exp(\mathbf{x}_i' \boldsymbol{\beta})
     = \exp(\beta_0 + \beta_1 x_{i1} + \ldots + \beta_k x_{ik})
\]</div>
<p>We create a <code class="docutils literal notranslate"><span class="pre">namedtuple</span></code> to store the observed values</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">RegressionModel</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;RegressionModel&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">create_regression_model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">n</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="c1"># Reshape y as a n_by_1 column vector</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">device_put</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">RegressionModel</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The log likelihood function of the Poisson regression is</p>
<div class="math notranslate nohighlight">
\[
\underset{\beta}{\max} \Big(
\sum_{i=1}^{n} y_i \log{\mu_i} -
\sum_{i=1}^{n} \mu_i -
\sum_{i=1}^{n} \log y! \Big)
\]</div>
<p>The full derivation can be found <a class="reference external" href="https://python.quantecon.org/mle.html#id2">here</a>.</p>
<p>The log likelihood function involves factorial, but JAX doesn’t have a readily available implementation to compute factorial directly.</p>
<p>In order to compute the factorial efficiently such that we can JIT it, we use</p>
<div class="math notranslate nohighlight">
\[
    n! = e^{\log(\Gamma(n+1))}
\]</div>
<p>since <a class="reference external" href="https://jax.readthedocs.io/en/latest/_autosummary/jax.lax.lgamma.html">jax.lax.lgamma</a> and <a class="reference external" href="https://jax.readthedocs.io/en/latest/_autosummary/jax.lax.exp.html">jax.lax.exp</a> are available.</p>
<p>The following function <code class="docutils literal notranslate"><span class="pre">jax_factorial</span></code> computes the factorial using this idea.</p>
<p>Let’s define this function in Python</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@jax</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span> <span class="nf">_factorial</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">jax</span><span class="o">.</span><span class="n">lax</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">lax</span><span class="o">.</span><span class="n">lgamma</span><span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

<span class="n">jax_factorial</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">vmap</span><span class="p">(</span><span class="n">_factorial</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now we can define the log likelihood function in Python</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@jax</span><span class="o">.</span><span class="n">jit</span>
<span class="k">def</span> <span class="nf">poisson_logL</span><span class="p">(</span><span class="n">β</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">y</span>
    <span class="n">μ</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">X</span> <span class="o">@</span> <span class="n">β</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">y</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">μ</span><span class="p">)</span> <span class="o">-</span> <span class="n">μ</span> <span class="o">-</span> <span class="n">jnp</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">jax_factorial</span><span class="p">(</span><span class="n">y</span><span class="p">)))</span>
</pre></div>
</div>
</div>
</div>
<p>To find the gradient of the <code class="docutils literal notranslate"><span class="pre">poisson_logL</span></code>, we again use <a class="reference external" href="https://jax.readthedocs.io/en/latest/_autosummary/jax.grad.html">jax.grad</a>.</p>
<p>According to <a class="reference external" href="https://jax.readthedocs.io/en/latest/notebooks/autodiff_cookbook.html#jacobians-and-hessians-using-jacfwd-and-jacrev">the documentation</a>,</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">jax.jacfwd</span></code> uses forward-mode automatic differentiation, which is more efficient for “tall” Jacobian matrices, while</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">jax.jacrev</span></code> uses reverse-mode, which is more efficient for “wide” Jacobian matrices.</p></li>
</ul>
<p>(The documentation also states that when matrices that are near-square, <code class="docutils literal notranslate"><span class="pre">jax.jacfwd</span></code> probably has an edge over <code class="docutils literal notranslate"><span class="pre">jax.jacrev</span></code>.)</p>
<p>Therefore, to find the Hessian, we can directly use <code class="docutils literal notranslate"><span class="pre">jax.jacfwd</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">G_poisson_logL</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">poisson_logL</span><span class="p">)</span>
<span class="n">H_poisson_logL</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">jacfwd</span><span class="p">(</span><span class="n">G_poisson_logL</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Our function <code class="docutils literal notranslate"><span class="pre">newton_raphson</span></code> will take a <code class="docutils literal notranslate"><span class="pre">RegressionModel</span></code> object
that has an initial guess of the parameter vector <span class="math notranslate nohighlight">\(\boldsymbol{\beta}_0\)</span>.</p>
<p>The algorithm will update the parameter vector according to the updating
rule, and recalculate the gradient and Hessian matrices at the new
parameter estimates.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">newton_raphson</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">β</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>

    <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">error</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># Initial error value</span>

    <span class="c1"># Print header of output</span>
    <span class="k">if</span> <span class="n">display</span><span class="p">:</span>
        <span class="n">header</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="s2">&quot;Iteration_k&quot;</span><span class="si">:</span><span class="s1">&lt;13</span><span class="si">}{</span><span class="s2">&quot;Log-likelihood&quot;</span><span class="si">:</span><span class="s1">&lt;16</span><span class="si">}{</span><span class="s2">&quot;θ&quot;</span><span class="si">:</span><span class="s1">&lt;60</span><span class="si">}</span><span class="s1">&#39;</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">header</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">header</span><span class="p">))</span>

    <span class="c1"># While loop runs while any value in error is greater</span>
    <span class="c1"># than the tolerance until max iterations are reached</span>
    <span class="k">while</span> <span class="n">jnp</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">error</span> <span class="o">&gt;</span> <span class="n">tol</span><span class="p">)</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">max_iter</span><span class="p">:</span>
        <span class="n">H</span><span class="p">,</span> <span class="n">G</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">H_poisson_logL</span><span class="p">(</span><span class="n">β</span><span class="p">,</span> <span class="n">model</span><span class="p">)),</span> <span class="n">G_poisson_logL</span><span class="p">(</span><span class="n">β</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
        <span class="n">β_new</span> <span class="o">=</span> <span class="n">β</span> <span class="o">-</span> <span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">H</span><span class="p">),</span> <span class="n">G</span><span class="p">))</span>
        <span class="n">error</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">β_new</span> <span class="o">-</span> <span class="n">β</span><span class="p">)</span>
        <span class="n">β</span> <span class="o">=</span> <span class="n">β_new</span>

        <span class="k">if</span> <span class="n">display</span><span class="p">:</span>
            <span class="n">β_list</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">t</span><span class="si">:</span><span class="s1">.3</span><span class="si">}</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">β</span><span class="o">.</span><span class="n">flatten</span><span class="p">())]</span>
            <span class="n">update</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">i</span><span class="si">:</span><span class="s1">&lt;13</span><span class="si">}{</span><span class="n">poisson_logL</span><span class="p">(</span><span class="n">β</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span><span class="si">:</span><span class="s1">&lt;16.8</span><span class="si">}{</span><span class="n">β_list</span><span class="si">}</span><span class="s1">&#39;</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">update</span><span class="p">)</span>

        <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Number of iterations: </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;β_hat = </span><span class="si">{</span><span class="n">β</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">β</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s try out our algorithm with a small dataset of 5 observations and 3
variables in <span class="math notranslate nohighlight">\(\mathbf{X}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
               <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
               <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
               <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
               <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>

<span class="c1"># Take a guess at initial βs</span>
<span class="n">init_β</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Create an object with Poisson model values</span>
<span class="n">poi</span> <span class="o">=</span> <span class="n">create_regression_model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># Use newton_raphson to find the MLE</span>
<span class="n">β_hat</span> <span class="o">=</span> <span class="n">newton_raphson</span><span class="p">(</span><span class="n">poi</span><span class="p">,</span> <span class="n">init_β</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Iteration_k  Log-likelihood  θ                                                           
-----------------------------------------------------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0            -4.3447622      [&#39;-1.49&#39;, &#39;0.265&#39;, &#39;0.244&#39;]
1            -3.5742413      [&#39;-3.38&#39;, &#39;0.528&#39;, &#39;0.474&#39;]
2            -3.3999526      [&#39;-5.06&#39;, &#39;0.782&#39;, &#39;0.702&#39;]
3            -3.3788646      [&#39;-5.92&#39;, &#39;0.909&#39;, &#39;0.82&#39;]
4            -3.3783559      [&#39;-6.07&#39;, &#39;0.933&#39;, &#39;0.843&#39;]
5            -3.3783555      [&#39;-6.08&#39;, &#39;0.933&#39;, &#39;0.843&#39;]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>6            -3.3783555      [&#39;-6.08&#39;, &#39;0.933&#39;, &#39;0.843&#39;]
Number of iterations: 7
β_hat = [-6.07848573  0.9334028   0.84329677]
</pre></div>
</div>
</div>
</div>
<p>As this was a simple model with few observations, the algorithm achieved
convergence in only 7 iterations.</p>
<p>The gradient vector should be close to 0 at <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\beta}}\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">G_poisson_logL</span><span class="p">(</span><span class="n">β_hat</span><span class="p">,</span> <span class="n">poi</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Array([[-2.55892529e-13],
       [-6.50313137e-13],
       [-5.01695907e-13]], dtype=float64)
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="mle-with-statsmodels">
<h2><a class="toc-backref" href="#id4"><span class="section-number">8.3. </span>MLE with <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code></a><a class="headerlink" href="#mle-with-statsmodels" title="Permalink to this heading">#</a></h2>
<p>We’ll use the Poisson regression model in <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code> to verify the results
obtained using JAX.</p>
<p><code class="docutils literal notranslate"><span class="pre">statsmodels</span></code> uses the same algorithm as above to find the maximum
likelihood estimates.</p>
<p>Now, as <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code> accepts only NumPy arrays, we can use the <code class="docutils literal notranslate"><span class="pre">__array__</span></code> method
of JAX arrays to convert it to NumPy arrays.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_numpy</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">__array__</span><span class="p">()</span>
<span class="n">y_numpy</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">__array__</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">stats_poisson</span> <span class="o">=</span> <span class="n">Poisson</span><span class="p">(</span><span class="n">y_numpy</span><span class="p">,</span> <span class="n">X_numpy</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">stats_poisson</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Optimization terminated successfully.
         Current function value: 0.675671
         Iterations 7
                          Poisson Regression Results                          
==============================================================================
Dep. Variable:                      y   No. Observations:                    5
Model:                        Poisson   Df Residuals:                        2
Method:                           MLE   Df Model:                            2
Date:                Mon, 11 Sep 2023   Pseudo R-squ.:                  0.2546
Time:                        00:25:11   Log-Likelihood:                -3.3784
converged:                       True   LL-Null:                       -4.5325
Covariance Type:            nonrobust   LLR p-value:                    0.3153
==============================================================================
                 coef    std err          z      P&gt;|z|      [0.025      0.975]
------------------------------------------------------------------------------
const         -6.0785      5.279     -1.151      0.250     -16.425       4.268
x1             0.9334      0.829      1.126      0.260      -0.691       2.558
x2             0.8433      0.798      1.057      0.291      -0.720       2.407
==============================================================================
</pre></div>
</div>
</div>
</div>
<p>The benefit of writing our own procedure, relative to statsmodels is that</p>
<ul class="simple">
<li><p>we can exploit the power of the GPU and</p></li>
<li><p>we learn the underlying methodology, which can be extended to complex situations where no existing routines are available.</p></li>
</ul>
<div class="exercise admonition" id="newton_mle1">

<p class="admonition-title"><span class="caption-number">Exercise 8.1 </span></p>
<section id="exercise-content">
<p>We define a quadratic model for a single explanatory variable by</p>
<div class="math notranslate nohighlight">
\[
    \log(\lambda_t) = \beta_0 + \beta_1 x_t + \beta_2 x_{t}^2
\]</div>
<p>We calculate the mean on the original scale instead of the log scale by exponentiating both sides of the above equation, which gives</p>
<div class="math notranslate nohighlight" id="equation-lambda-mle">
<span class="eqno">(8.1)<a class="headerlink" href="#equation-lambda-mle" title="Permalink to this equation">#</a></span>\[    \lambda_t = \exp(\beta_0 + \beta_1 x_t + \beta_2 x_{t}^2)\]</div>
<p>Simulate the values of <span class="math notranslate nohighlight">\(x_t\)</span> by sampling from a normal distribution and <span class="math notranslate nohighlight">\(\lambda_t\)</span> by using <a class="reference internal" href="#equation-lambda-mle">(8.1)</a> and the following constants:</p>
<div class="math notranslate nohighlight">
\[
    \beta_0 = -2.5,
    \quad
    \beta_1 = 0.25,
    \quad
    \beta_2 = 0.5
\]</div>
<p>Try to obtain the approximate values of <span class="math notranslate nohighlight">\(\beta_0,\beta_1,\beta_2\)</span>, by simulating a Poisson Regression Model such that</p>
<div class="math notranslate nohighlight">
\[
      y_t \sim {\rm Poisson}(\lambda_t)
      \quad \text{for all } t.
\]</div>
<p>Using our <code class="docutils literal notranslate"><span class="pre">newton_raphson</span></code> function on the data set <span class="math notranslate nohighlight">\(X = [1, x_t, x_t^{2}]\)</span> and
<span class="math notranslate nohighlight">\(y\)</span>, obtain the maximum likelihood estimates of <span class="math notranslate nohighlight">\(\beta_0,\beta_1,\beta_2\)</span>.</p>
<p>With a sufficient large sample size, you should approximately
recover the true values of of these parameters.</p>
</section>
</div>
<div class="solution dropdown admonition" id="mle-solution-1">

<p class="admonition-title">Solution to<a class="reference internal" href="#newton_mle1"> Exercise 8.1</a></p>
<section id="solution-content">
<p>Let’s start by defining “true” parameter values.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">β_0</span> <span class="o">=</span> <span class="o">-</span><span class="mf">2.5</span>
<span class="n">β_1</span> <span class="o">=</span> <span class="mf">0.25</span>
<span class="n">β_2</span> <span class="o">=</span> <span class="mf">0.5</span>
</pre></div>
</div>
</div>
</div>
<p>To simulate the model, we sample 500,000 values of <span class="math notranslate nohighlight">\(x_t\)</span> from the standard normal distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">seed</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">500_000</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">key</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We compute <span class="math notranslate nohighlight">\(\lambda\)</span> using <a class="reference internal" href="#equation-lambda-mle">(8.1)</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">λ</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">β_0</span> <span class="o">+</span> <span class="n">β_1</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">β_2</span> <span class="o">*</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s define <span class="math notranslate nohighlight">\(y_t\)</span> by sampling from a Poisson distribution with mean as <span class="math notranslate nohighlight">\(\lambda_t\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">poisson</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">λ</span><span class="p">,</span> <span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s try to recover the true parameter values using the Newton-Raphson
method described above.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">jnp</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="p">),</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>

<span class="c1"># Take a guess at initial βs</span>
<span class="n">init_β</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Create an object with Poisson model values</span>
<span class="n">poi</span> <span class="o">=</span> <span class="n">create_regression_model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="c1"># Use newton_raphson to find the MLE</span>
<span class="n">β_hat</span> <span class="o">=</span> <span class="n">newton_raphson</span><span class="p">(</span><span class="n">poi</span><span class="p">,</span> <span class="n">init_β</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Iteration_k  Log-likelihood  θ                                                           
-----------------------------------------------------------------------------------------
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0            -4.5444745e+07  [&#39;-1.49&#39;, &#39;0.312&#39;, &#39;0.794&#39;]
1            -1.6303734e+07  [&#39;-2.42&#39;, &#39;0.311&#39;, &#39;0.79&#39;]
2            -5689832.6      [&#39;-3.22&#39;, &#39;0.31&#39;, &#39;0.78&#39;]
3            -1869457.7      [&#39;-3.73&#39;, &#39;0.306&#39;, &#39;0.756&#39;]
4            -510284.64      [&#39;-3.71&#39;, &#39;0.297&#39;, &#39;0.705&#39;]
5            -28066.381      [&#39;-3.2&#39;, &#39;0.283&#39;, &#39;0.63&#39;]
6            127470.33       [&#39;-2.77&#39;, &#39;0.268&#39;, &#39;0.563&#39;]
7            163044.64       [&#39;-2.57&#39;, &#39;0.257&#39;, &#39;0.52&#39;]
8            166608.12       [&#39;-2.51&#39;, &#39;0.252&#39;, &#39;0.503&#39;]
9            166666.4        [&#39;-2.5&#39;, &#39;0.251&#39;, &#39;0.5&#39;]
10           166666.42       [&#39;-2.5&#39;, &#39;0.251&#39;, &#39;0.5&#39;]
11           166666.42       [&#39;-2.5&#39;, &#39;0.251&#39;, &#39;0.5&#39;]
Number of iterations: 12
β_hat = [-2.50016027  0.25079345  0.50008394]
</pre></div>
</div>
</div>
</div>
<p>The maximum likelihood estimates are similar to the true parameter values.</p>
</section>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                    </div>
                    
                </main> <!-- .page__content -->
                


                <footer class="qe-page__footer">

                    <p><a href="https://creativecommons.org/licenses/by-sa/4.0/"><img src="https://licensebuttons.net/l/by-sa/4.0/80x15.png"></a></p>

                    <p>Creative Commons License &ndash; This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International.</p>

                </footer> <!-- .page__footer -->

            </div> <!-- .page -->

            

            
            <div class="qe-sidebar bd-sidebar inactive" id="site-navigation">

                <div class="qe-sidebar__header">


                    Contents

                </div>

                <nav class="qe-sidebar__nav" id="qe-sidebar-nav" aria-label="Main navigation">
                    <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="about.html">
   1. About
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="jax_intro.html">
   2. An Introduction to JAX
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="newtons_method.html">
   3. Newton’s Method via JAX
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="markov_asset.html">
   4. An Asset Pricing Problem
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Simulation
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="inventory_dynamics.html">
   5. Inventory Dynamics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kesten_processes.html">
   6. Kesten Processes and Firm Dynamics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="wealth_dynamics.html">
   7. Wealth Distribution Dynamics
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Data and Empirics
 </span>
</p>
<ul class="current nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1 current active active">
  <a class="current reference internal" href="#">
   8. Maximum Likelihood Estimation
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Dynamic Programming
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="short_path.html">
   9. Shortest Paths
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="opt_invest.html">
   10. Optimal Investment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="opt_savings.html">
   11. Optimal Savings
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ifp_egm.html">
   12. Endogenous Grid Method
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="arellano.html">
   13. Default Risk and Income Fluctuations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="aiyagari_jax.html">
   14. The Aiyagari Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cake_eating_numerical.html">
   15. Cake Eating: Numerical Methods
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Other
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="troubleshooting.html">
   16. Troubleshooting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="zreferences.html">
   17. References
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="status.html">
   18. Execution Statistics
  </a>
 </li>
</ul>

                </nav>

                <div class="qe-sidebar__footer">

                </div>

            </div> <!-- .sidebar -->
            
        </div> <!-- .main -->

        <div class="qe-toolbar">

            <div class="qe-toolbar__inner">

                <ul class="qe-toolbar__main">
                    <li data-tippy-content="Table of Contents" class="btn__sidebar"><i data-feather="menu"></i></li>
                    <li data-tippy-content="Home"><a href="intro.html"><i data-feather="home"></i></a></li>
                    <li class="btn__qelogo"><a href="https://quantecon.org" title=""><span class="show-for-sr">QuantEcon</span></a></li>
                </ul>

                <ul class="qe-toolbar__links">
                    <li class="btn__search">
                        <form action="search.html" method="get">
                            <input type="search" class="form-control" name="q" id="search-input" placeholder="Search..." aria-label="Search..." autocomplete="off" accesskey="k">
                            <i data-feather="search" id="search-icon"></i>
                        </form>
                    </li>
                    <li data-tippy-content="Fullscreen" class="btn__fullscreen"><i data-feather="maximize"></i></li>
                    <li data-tippy-content="Increase font size" class="btn__plus"><i data-feather="plus-circle"></i></li>
                    <li data-tippy-content="Decrease font size" class="btn__minus"><i data-feather="minus-circle"></i></li>
                    <li data-tippy-content="Change contrast" class="btn__contrast"><i data-feather="sunset"></i></li>
                    <li data-tippy-content="Download Notebook"><a href="/_notebooks/mle.ipynb" download><i data-feather="download-cloud"></i></a></li>
                    <li class="settings-button" id="settingsButton"><div data-tippy-content="Launch Notebook"><i data-feather="play-circle"></i></div></li>
                        <li class="download-pdf" id="downloadButton"><i data-feather="file"></i></li>
                    <li data-tippy-content="View Source"><a target="_blank" href="https://github.com/QuantEcon/lecture-jax/blob/main/lectures/mle.md" download><i data-feather="github"></i></a></li>
                </ul>

            </div>

        </div> <!-- .toolbar -->
        <div id="downloadPDFModal" style="display: none;">
            <ul class="pdf-options" style="display: block;">
                <li class="download-pdf-book" onClick="window.print()">
                    <p>Lecture (PDF)</p>
                </li>
                <li class="download-pdf-file">
                    <a href="/_pdf/quantecon-jax.pdf" download><p>Book (PDF)</p></a>
                </li>
            </ul>
        </div>
        <div id="settingsModal" style="display: none;">
            <p class="modal-title"> Notebook Launcher </p>
            <div class="modal-desc">
            <p>
                Choose public or private cloud service for "Launch" button.
            </p>
            </div>
            <p class="modal-subtitle">Select a server</p>
            <ul class="modal-servers">
            <li class="active launcher-public">
                <span class="label">Public</span>
                <select id="launcher-public-input">
                
                    <option value="https://mybinder.org/v2/gh/QuantEcon/lecture-jax.notebooks/master?urlpath=tree/mle.ipynb">BinderHub</option>
                
                    <option value="https://colab.research.google.com/github/QuantEcon/lecture-jax.notebooks/blob/master/mle.ipynb">Colab</option>
                
                </select>
                <i class="fas fa-check-circle"></i>
            </li>
            <li class="launcher-private">
                <span class="label">Private</span>
                <input type="text" id="launcher-private-input" data-repourl="https://github.com/QuantEcon/lecture-jax.notebooks" data-urlpath="tree/lecture-jax.notebooks/mle.ipynb" data-branch=master>
                <i class="fas fa-check-circle"></i>
            </li>
            </ul>
            <p class="launch"><a href="https://mybinder.org/v2/gh/QuantEcon/lecture-jax.notebooks/master?urlpath=tree/mle.ipynb" id="advancedLaunchButton" target="_blank">Launch Notebook</a></p>
            <script>
                // QuantEcon Notebook Launcher
                const launcherTypeElements = document.querySelectorAll('#settingsModal .modal-servers li');
                // Highlight the server type if previous selection exists
                if (typeof localStorage.launcherType !== 'undefined') {
                  for (var i = 0; i < launcherTypeElements.length; i++) {
                    launcherTypeElements[i].classList.remove('active');
                    if ( launcherTypeElements[i].classList.contains(localStorage.launcherType) ) {
                      launcherTypeElements[i].classList.add('active');
                    }
                  }
                }
                // Highlight server type on click and set local storage value
                for (var i = 0; i < launcherTypeElements.length; i++) {
                  launcherTypeElements[i].addEventListener('click', function() {
                    for (var j = 0; j < launcherTypeElements.length; j++) {
                      launcherTypeElements[j].classList.remove('active');
                    }
                    this.classList.add('active');
                    if ( this.classList.contains('launcher-private') ) {
                      localStorage.launcherType = 'launcher-private';
                    } else if ( this.classList.contains('launcher-public') ) {
                      localStorage.launcherType = 'launcher-public';
                    }
                    setLaunchServer();
                  })
                }
                const launcherPublic = document.getElementById('launcher-public-input');
                const launcherPrivate = document.getElementById('launcher-private-input');
                const pageName = "mle";
                const repoURL = "https://github.com/QuantEcon/lecture-jax.notebooks";
                const urlPath = "tree/lecture-jax.notebooks/mle.ipynb";
                const branch = "master"
                const launchNotebookLink = document.getElementById('advancedLaunchButton');

                // Highlight public server option if previous selection exists
                if (typeof localStorage.launcherPublic !== 'undefined') {
                  launcherPublic.value = localStorage.launcherPublic;
                }
                // Update local storage upon public server selection
                launcherPublic.addEventListener('change', (event) => {
                  setLaunchServer();
                });
                // Populate private server input if previous entry exists
                if (typeof localStorage.launcherPrivate !== 'undefined') {
                  launcherPrivate.value = localStorage.launcherPrivate;
                }
                // Update local storage when a private server is entered
                launcherPrivate.addEventListener('input', (event) => {
                  setLaunchServer();
                });

                // Function to update the "Launch Notebook" link href
                function setLaunchServer() {
                  launchNotebookLink.removeAttribute("style")
                  if ( localStorage.launcherType == 'launcher-private' ) {
                    let repoPrefix = "/jupyter/hub/user-redirect/git-pull?repo=" + repoURL + "&branch=" + branch + "&urlpath=" + urlPath;
                    launcherPrivateValue = launcherPrivate.value
                    if (!launcherPrivateValue) {
                        launchNotebookLink.removeAttribute("href")
                        launchNotebookLink.style.background = "grey"
                        return
                    }
                    localStorage.launcherPrivate = launcherPrivateValue;
                    privateServer = localStorage.launcherPrivate.replace(/\/$/, "")
                    if (!privateServer.includes("http")) {
                        privateServer = "http://" + privateServer
                    }
                    launchNotebookLinkURL = privateServer + repoPrefix;
                  } else if ( localStorage.launcherType == 'launcher-public' ) {
                    launcherPublicValue = launcherPublic.options[launcherPublic.selectedIndex].value;
                    localStorage.launcherPublic = launcherPublicValue;
                    launchNotebookLinkURL = localStorage.launcherPublic;
                  }
                  if (launchNotebookLinkURL) launchNotebookLink.href = launchNotebookLinkURL;
                }
                // Check if user has previously selected a server
                if ( (typeof localStorage.launcherPrivate !== 'undefined') || (typeof localStorage.launcherPublic !== 'undefined') ) {
                  setLaunchServer();
                }
                </script>

        </div>

    </div> <!-- .wrapper-->
  </body>
</html>